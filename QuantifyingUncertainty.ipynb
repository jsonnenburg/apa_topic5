{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XRX2K88MB3c"
   },
   "source": [
    "<h1>Quantifying Uncertainty <br> in Deep Learning Models</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mJ-GqwnMB3p"
   },
   "source": [
    "Michelle Laubinger and Johann Sonnenburg\n",
    "                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BepiyPYMB3r"
   },
   "source": [
    "Applied Predictive Analytics, Summer 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIILjMryMB3s"
   },
   "source": [
    "### Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Literature Review](#litreview)\n",
    "3. [Quantifying Uncertainty](#quantuncertainty)\n",
    "    1. [Bayesian Inference](#bayesianstats)\n",
    "    2. [Variational Inference](#varinference) \n",
    "    3. [Monte Carlo Dropout](#mcdropout)\n",
    "4. [Data](#data)\n",
    "5. [Methodology](#methods)\n",
    "    1. [Variational Inference for Bayesian Neural Networks](#bnn)\n",
    "    2. [Dropout Neural Network](#dropoutnet)\n",
    "6. [Results](#results)\n",
    "7. [Discussion](#discussion)\n",
    "8. [Conclusion](#conclusion)\n",
    "9. [Bibliography](#bibliography)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Anx383MB3t"
   },
   "source": [
    "### 1. Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "Standard deep learning models are typically viewed as deterministic functions where we obtain point estimators of the models' parameters and the predictions. Essentially, this means that we have to assume that a model is 100 percent certain about every prediction that it puts out. Thus, we are unable to determine any kind of uncertainty about these predictions. In many applications it is however necessary to be able to tell whether a model is certain about its output. If a model were to exhibit high uncertainty, this would imply that we should be careful when using the model's predictions as a base for decision-making. Furthermore, this would lead us to consider collecting more diverse data or changing the model altogether. \n",
    "\n",
    "In the context of credit risk analysis, we are concerned with evaluating the probability of default (PD) of a client to assess whether that client is creditworthy or not. However, the PD does not correspond to the (un)certainty that we have in a prediction, a mistake that is commonly made. Introducing a measure that expresses confidence in predictions would be beneficial, especially in a classification problem such as the one examined in this study. Consequently, corner cases could be identified, which could then be reevaluated by a more sophisticated model or a human expert.\n",
    "\n",
    "Research about uncertainty quantification has gained significant traction in the last few years, with many applications in the fields of medical diagnosis, autonomous driving, and critical systems. It is also being applied to reinforcement and active learning with great success.\n",
    "Credit risk classification is another problem setting for which the ability to quantify the uncertainty in deep learning models is of particularly high interest, since there exists a direct link between predictive accuracy and business performance. Being a highly regulated business sector, where transparency is required by law, uncertainty quantification could help mitigate the prevailing perception that deep learning models are black box methods and thus inappropriate in a credit risk setting.\n",
    "\n",
    "Only recent research has allowed for the incorporation of Bayesian techniques into the standard deep learning toolbox. Bayesian methods have been known for some time, yet they have not been used to their full potential up until recently. Primarily, this was due to computational limitations, as Bayesian inference is a complex computational task that has traditionally been time- and resource-consuming, making it unattractive for practical purposes. While the heavily increased efficiency does come at a price, it has been shown to greatly increase transparency and predictive performance in a variety of problem settings.\n",
    "\n",
    "In this application, we aim to provide a comprehensive summary of the relevant literature regarding uncertainty quantification in machine learning. Additionally, we implement two selected techniques used to quantify uncertainty in deep neural networks using financial data. \n",
    " \n",
    "This study is structured as follows: Chapter 2 comprises a detailed survey of the existing literature. The third chapter introduces the problem of quantifying uncertainty in deep learning and provides a theoretical background for the methods we later employ. Chapter 4 illustrates the way we prepare the data, Chapter 5 details the methodology we use in this study and the implementation of the models, and Chapter 6 reports the results. Finally, Chapter 7 provides a short discussion of our findings and Chapter 8 concludes our study with a brief summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jnzzpA_MB3v"
   },
   "source": [
    "### 2. Literature Review <a name=\"litreview\"></a>\n",
    "\n",
    "The quantification of uncertainty in deep learning has been the subject of a large body of research in recent years. Several studies provide an overview of the existing methods coupled with the required theoretical foundations. Gal (2016) lays out a comprehensive summary of existing techniques and gives an extensive theoretical introduction to what uncertainty is in the context of machine learning and to the mathematical theories behind the most commonly applied methods. Notably, he provides an intuition on the link between deep learning models and Gaussian processes and summarizes the historical literature related to Gaussian processes before moving to traditional techniques for performing variational inference (VI), which represent updates of these historical ideas. Surveying how inference was conventionally performed in Bayesian neural networks, Gal (2016) highlights shortcomings of these established techniques, such as the inability to scale to large data or to adapt to complex models. He emphasizes the lack of practicality of most of these techniques, rendering them unsuitable for most practical applications. Moving on to approximate variational techniques (Blundell et al., 2015, Graves, 2011, Kingma and Welling, 2013), he outlines how these laid the groundwork for modern implementations of Bayesian neural networks which overcome the before-mentioned shortcomings. In this light, he introduces his own work done in Gal and Ghahramani (2016a), Monte Carlo (MC) dropout, as a modern and practical alternative that is equivalent to performing approximate inference. Comparing variational inference, probabilistic backpropagation (Blundell et al., 2015), and MC dropout in terms of performance and data fit on several benchmarking problems, he shows the superior performance of dropout compared to other techniques. Furthermore, Gal (2016) introduces the variation ratio as a measure of uncertainty in classification problems which is applicable to MC dropout. Finally, he outlines the applications of uncertainty quantification in Bayesian convolutional neural networks and Bayesian recurrent neural networks and provides examples for several applications of these techniques, while illustrating their use in the form of experiments. Lastly, he supplies practical advice for using MC dropout and summarizes which factors influence the uncertainty quality in the implementation of neural networks.\n",
    "\n",
    "In a systematic survey of the literature covering over 2500 papers from 2010 to mid-2020, Abdar et al. (2021) aim to review the most important papers on uncertainty quantification and its applications in the fields of, among others, computer vision, medical image analysis, and natural language processing. To this end, they additionally provide a theoretical introduction to the subject of uncertainty quantification, dealing with MC dropout, Markov Chain Monte Carlo, VI, Bayes by Backprop, and variational autoencoders. Similar to Gal (2016), they provide a background to measuring uncertainty in predictive modeling and discuss fundamental methods such as deep Gaussian processes. Furthermore, they summarize the literature on Bayesian reinforcement and active learning.\n",
    "\n",
    "Similarly, Hüllermeier and Waegeman (2021) provide an introduction to uncertainty quantification in machine learning. In addition to reviewing common methods for handling uncertainty, they study comprehensively the sources of uncertainty in supervised learning. They specifically focus on how different methods can distinguish different forms of uncertainty. Finally, Hüllermeier and Waegeman (2021) point out the lack of awareness for model uncertainty in standard machine learning approaches and the resulting overconfidence in model outputs.\n",
    "\n",
    "In this study, we will focus on two methods of performing Bayesian inference in detail. One is an approach implementing automatic variational inference via Automatic Differentiation Variational Inference (ADVI, as introduced by Kucukelbir et al., 2015), while the other is Monte Carlo dropout (Gal and Ghahramani, 2016a).\n",
    "\n",
    "Deep learning models are closely connected to the concept of Gaussian processes. If we were to place a probability distribution over each weight within a neural network, a Gaussian process could be recovered in the limit of infinitely many weights (Neal, 1995). In the slightly more realistic setting of a finite number of weights, we can still obtain model uncertainty by placing probability distributions over these weights. We call such a model a Bayesian neural network (MacKay, 1992). Traditionally, these models and their newer derivatives (e.g., Kingma and Welling, 2013, or Blundell et al., 2015), are often difficult to work with and lack practicality, as highlighted by Gal (2016).\n",
    "\n",
    "One of the key tasks in Bayesian inference is numerical integration. Due to the limited tractability of analytical solutions and their high computational efforts (in cases where they do happen to be tractable), approximate Bayesian inference has gained popularity over the years. Minka (2001) divided methods for approximate Bayesian inference into deterministic methods and nondeterministic methods. The latter randomly sample from the integrand to stochastically estimate the integral. Well known examples of this are Markov Chain Monte Carlo (MCMC) methods such as Metropolis sampling and Gibbs sampling (Wainwright and Jordan, 2008). Deterministic methods on the other hand attempt to find an approximation of the integrand by using densities whose integrals are known exactly. Variational methods fall into this category, which constitute a family of optimization-based problem formulations and their related solution techniques. The goal of variational inference is approximating a conditional density of latent variables given observed variables using optimization. To manage complexity, a family of densities is proposed over the latent variables that is flexible enough to entail a density as close as possible to the true posterior, but simple enough to enable efficient optimization (Blei et al., 2018). Here, the Kullback-Leibler divergence is commonly used as a similarity measure to evaluate the proximity of the approximate density and the true posterior. Specifically, VI comprises specifying a parameterized family of distributions that seems appropriate, computing the corresponding objective function, taking the derivatives, and running a gradient-based or coordinate-ascent optimization (Kucukelbir, 2017). Using Automatic Differentiation Variational Inference (ADVI), these computations can be automated, leaving the user with the task of specifying the model while ADVI takes care of generating the corresponding variational algorithm. This enables the use of common machine learning models such as generalized linear models, mixture models, Gaussian process models etc. \n",
    "\n",
    "Hinton et al. (2012) introduce dropout as a regularization technique specifically to prevent hidden units from developing complex co-adaptations on the training data set. Dropout can also be viewed as a highly efficient way of performing model averaging with neural networks. Predictions are performed at test time by using a “mean network” where all hidden units are used but the outgoing weights are scaled by the respective dropout probability. Hinton et al. (2012) show that dropout improves model performance on many benchmark tasks.\n",
    "\n",
    "Elaborating on the work done by Hinton et al. (2012), Srivastava et al. (2014) perform an in-depth analysis of the application of dropout to various supervised learning problems. They find that training a network with dropout and predicting using the mean network “leads to [a] significantly lower generalization error on a wide variety of classification problems compared to training with other regularization methods” (Srivastava et al., 2014, p. 1931). However, they note that applying dropout results in an increase in training time compared to networks without dropout due to the parameter updates being very noisy. Additionally, they provide a practical guide to training dropout networks.\n",
    "\n",
    "Gal and Ghahramani (2016a), following Srivastava et al. (2014), lay the groundwork for a new approach for performing approximate inference by establishing a connection between dropout and variational inference. They develop a novel theoretical framework for using dropout in deep neural networks called MC dropout and show that it is mathematically equivalent to approximate Bayesian inference in deep Gaussian processes. Previously, dropout was motivated by an evolutional theory on sexual reproduction (Srivastava et al., 2014). Hence, Gal and Ghahramani (2016a) are the first to provide a mathematical foundation for the technique. Crucially, they show that dropout can be used to model uncertainty in any neural network that applies this type of regularization in the required fashion. This new approach overcomes previous limitations of uncertainty modeling related to computational costs and test performance. Illustrating how model uncertainty can be modeled in dropout neural networks, they additionally study uncertainty quantification with dropout by examining various network architectures on regression and classification tasks such as MNIST. Gal and Ghahramani (2016a) confirm that using dropout can provide an improvement in data fit and performance compared to existing state-of-the-art methods such as variational inference or probabilistic backpropagation.\n",
    "\n",
    "As we will use a credit risk data set to illustrate different ways of quantifying uncertainty in deep learning models, we provide a concise overview of the relevant literature. Tarashev (2009) emphasizes the importance of uncertainty quantification in a credit risk setting, by finding that ignoring parameter estimation noise leads to a severe understatement of the correct value-at-risk, which measures risk of loss for investments.\n",
    "\n",
    "Employing several different prediction models to analyze over 110,000 observations on enterprise defaults from a European bank, Addo et al. (2018) find that deep learning models do not outperform tree-based classifiers. Among their prediction models are four different deep learning models, one of which makes use of dropout regularization. Addo et al. (2018) note that transparency is of great importance in the credit industry and that models are required to incorporate it to ensure that they work properly. This is relevant because predictive accuracy and returns are directly related in this industry, but also to avoid discrimination.\n",
    "\n",
    "Similarly, Sirignano et al. (2018) utilize deep learning models to analyze US mortgage data comprising over 120 million observations. They note that deep learning models are especially appropriate for this type of financial modeling as they are able to uncover highly nonlinear influences of variables on the target and potential interaction effects among them. Notably, they employ a relatively large deep neural network and apply dropout regularization. \n",
    "\n",
    "Finally, Albanesi and Vamossy (2019) find a deep learning model to outperform standard credit scoring models for predicting consumer default. They point out the evident financial motivation for using better models and find their neural network to improve predictive accuracy while increasing transparency and accountability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tehYS9r4MB3z"
   },
   "source": [
    "### 3. Quantifying Uncertainty <a name=\"quantuncertainty\"></a>\n",
    "\n",
    "In predictive modelling, uncertainty can be classified into two categories: aleatoric and epistemic uncertainty. \n",
    "Aleatoric uncertainty, which is sometimes also referred to as statistical uncertainty, describes the randomness of an experiment. More specifically, it characterizes the variability in the outcome of an experiment that is caused by random effects. Consequently, aleatoric uncertainty can be seen as a property of the underlying data distribution, making it irreducible due to the stochastic relationship between the covariates and the outcome. Aleatoric uncertainty also captures noise sources such as measurement noise - noise that cannot be explained away even if more data were available (although this uncertainty can be reduced through the use of higher precision sensors for example). \n",
    " \n",
    "In contrast, epistemic uncertainty occurs due to faulty or scarce knowledge which leads to models being incomplete, noisy, discordant, or multimodal. It essentially entails the amount of information about a hypothesis that would be gained through knowledge of the true outcome. It can be formulated as a probability distribution over the model parameters and expressed in terms of likelihood. For classification problems, a softmax likelihood can be used. Epistemic uncertainty reduces as the amount of observed data increases, hence it is also called “reducible uncertainty”. It can be thought of as a way to express confidence in the model structure. If we are able to quantify how certain the model is about its predictions and its parameters, we can use this information to compare different models and choose parameters that lead to more certain predictions.\n",
    "\n",
    "Conclusively, predictive uncertainty can be formulated as\n",
    "\n",
    "$$PU = EU + AU,$$\n",
    "\n",
    "where $PU$ is the predictive uncertainty, $EU$ is the epistemic uncertainty, and $AU$ is the aleatoric uncertainty.\n",
    " \n",
    "When using  neural networks for predictive tasks like binary classification, our model output expresses certainty by indicating the probability with which an outcome is likely to happen. Uncertainty quantification takes this one step further by expressing the certainty in that probability. Moreover, probabilistic modeling not only captures the uncertainty about the outcome, it is able to express (epistemic) uncertainty about each parameter of the model - the network weights in the context of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbTuPg2cMB34"
   },
   "source": [
    "### 3a. Bayesian Inference <a name=\"bayesianstats\"></a>\n",
    "\n",
    "Contrary to the frequentist approach to statistics, Bayesian models incorporate our belief or our uncertainty about the distribution of the unknown parameter before observing any data. This is called the prior distribution $p(\\omega)$ over the unknown parameters, the weights $\\omega$ in the case of a neural network. When we observe data, consisting of the feature matrix $\\mathbf{X}$ and the target matrix $\\mathbf{Y}$, we can update this prior belief to fit the data better using the observational model $p(\\mathbf{Y}|\\mathbf{X}, \\omega)$, which coincides with the likelihood of the model. This updated probability distribution is proportional to the posterior distribution. We normalize the posterior by dividing it by the marginal distribution of the data which is also called the evidence. In practice, the evidence is always unknown (Gelman et al., 1995). Formally, we utilize Bayes' theorem to compute the posterior distribution $p(\\omega|\\mathbf{X},\\mathbf{Y})$ as\n",
    "\n",
    "$$p(\\omega|\\mathbf{X},\\mathbf{Y}) = \\frac{p(\\mathbf{Y}|\\mathbf{X}, \\omega) p(\\omega)}{p(\\mathbf{Y}|\\mathbf{X})}.$$\n",
    "\n",
    "Thus, we \"learn\" the distribution of the unknown parameters by updating our prior knowledge with the observed data to obtain the posterior distribution.\n",
    "\n",
    "We can then use this posterior predictive distribution to predict the output $y^*$ given a new input point $x^*$ as \n",
    "\n",
    "$$ p(y^*|x^*) = \\int p(y^*|x^*, \\omega)p(\\omega|\\mathbf{X},\\mathbf{Y})d\\omega,$$\n",
    "\n",
    "which is called performing *inference* (Gal 2016).\n",
    "\n",
    "Bayesian models typically require a carefully chosen and tuned prior distribution based on a priori knowledge. At times when we lack this knowledge, we would use an uninformative prior which does not convey any information (although it should be mentioned that no prior is truly uninformative). In this application, we consider an uninformative Gaussian prior defined through our chosen length-scale, which will be elaborated on later, as done in Gal and Ghahramani (2016a). While Gaussian priors are typically more suitable for regression problems, they can be applied to classification problems as well (Neal, 1998)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuAN9YZzMB37"
   },
   "source": [
    "### 3b. Variational Inference <a name=\"varinference\"></a>\n",
    "\n",
    "At first glance, using a Bayesian approach to learning in neural network may seem counterintuitive, since specifying a prior for the neural network weights based on knowledge we have about their relationship appears complicated at best. However, MacKay (1992) shows that simply specifying a prior that models the weights as coming from a Gaussian proves sufficient. Still, even for small data sets and networks, obtaining the posterior often becomes intractable due to the nonlinear relationship between the network weights, as pointed out by Bishop (2006). Computationally heavy approximation techniques are required to yield results which makes using such traditional methods for larger data sets inefficient or even impossible. \n",
    "In modern Bayesian statistics, models' posterior distributions are increasingly difficult to compute and analytical solutions often become intractable. To overcome these problems, approximation techniques have been extensively studied and developed.\n",
    "MCMC sampling methods have likely received the most attention, but their scalability to large data sets or complex models is lacking due to high computational efforts (Blei et al., 2018). In those instances, variational inference (VI) has proven to be an alternative approach that uses less computational power. Rather than sampling Markov chains, VI relies on optimization, more specifically on the minimization of the Kullback-Leibler (KL) divergence, which is a measure of similarity between two probability distributions. \n",
    "The goal of variational inference is to approximate a conditional density of latent variables given observed variables using optimization. To manage complexity, a family of densities is proposed over the latent variable, that is flexible enough to entail a density as close as possible to the true posterior, but simple enough to enable efficient optimization (Blei et al., 2018).\n",
    " \n",
    "Hence, the goal is to estimate a function $y=f(x)$ that is likely to have generated the data. A distribution $p(f)$ is defined that reflects the likelihood of functions that are likely to generate the data according to prior beliefs. Next, a likelihood $p(\\mathbf{Y}|f,\\mathbf{X})$ is defined that captures the data-generating process of the observations, conditional on a specific function. A posterior distribution $p(f|\\mathbf{Y},\\mathbf{X})$ is then sought that represents the most likely functions given the observed data. This distribution can subsequently be used to predict outputs for new input points by integrating over all possible functions $f$.\n",
    "In many cases, this integral needs to be approximated, which is done by conditioning the model on a finite set of random variables $\\omega$. This implies the assumption that the model depends on these variables alone. Because the distribution $p(\\omega|\\mathbf{X}, \\mathbf{Y})$ can mostly not be evaluated analytically, a variational distribution $q(\\omega)$ is used to approximate the posterior distribution obtained from the original model. The Kullback-Leibler divergence is used as a measure of similarity between these two distributions as $\\mbox{KL}(q(\\omega)||p(\\omega|\\mathbf{X}, \\mathbf{Y})$. Minimizing the Kullback-Leibler divergence (maximizing the similarity between the approximate and the true posterior) is the same as maximizing the log evidence lower bound with respect to the variational parameters defining $q(\\omega)$. This computational procedure is known as variational inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbOfG48tMB39"
   },
   "source": [
    "### 3c. Monte Carlo Dropout <a name=\"mcdropout\"></a>\n",
    "\n",
    "#### From Stochastic Regularization Technique to Approximating Bayesian Neural Networks\n",
    "Gal (2016) highlights several challenges that arise when implementing approximate inference techniques for practical applications. These include:\n",
    "1. Scalability; the technique should scale well to large data,\n",
    "2. Adaptability; the technique should easily adapt to complex models,\n",
    "3. Deployability; the technique should not necessitate the change of existing model architectures or objectives,\n",
    "4. Practicality; The technique should be easy for practitioners without expert knowledge to comprehend and apply.\n",
    "\n",
    "Any technique that does not satisfy these requirements will, according to Gal (2016), simply not be used in industry applications.\n",
    "\n",
    "The approach employed by Gal (2016) to model uncertainty makes use of a stochastic regularization technique (SRT) to model uncertainty.\n",
    "In deep learning, regularization traditionally refers to a penalty term that is added to the loss function to impose an additional cost on the optimization function with the goal of preventing overfitting. \n",
    "In a broader, updated sense it is \"any modification we make to a learning algorithm that is intended to reduce its test error but not its training error\" (Goodfellow et al., 2016, Ch. 5). An example for such a modification that does not involve a penalty term is early stopping.\n",
    "Stochastic regularization extends traditional regularization techniques by introducing randomness into a model through, e.g., stochastically varying the model architecture for each batch during training time.\n",
    "\n",
    "SRTs include dropout (Hinton et al., 2012), multiplicative Gaussian noise (Srivastava et al., 2014), and dropConnect (Wan et al., 2013). Using SRTs it is possible to generate varying outputs by using the model during test time the same way it is used during training time: the model structure is stochastically varied, resulting in differing predictions. This allows for obtaining an approximative predictive distribution. We can then compute empirical estimates for the moments of this distribution, including the mean and the variance, which will allow us to quantify a model's uncertainty on a case-by-case basis. As SRTs are extremely widespread, the implication of this approach is that we will be able to model uncertainty in a straightforward way in any network architecture that makes use of SRTs.\n",
    "\n",
    "Srivastava et al. (2014) formalized dropout as a computationally efficient alternative to the idea of using an ensemble of deep learning models to reduce overfitting. Because deep learning models are increasingly large and require a long time to train, combining the outputs from a high number of them is prohibitively expensive in terms of time and computational resources. The key idea of dropout is to randomly drop units along with their associated connections with a set probability for each batch during training time to prevent the units from overly co-adapting. At test time, a single network with scaled-down weights is used. Here, the outgoing weights from a node are multiplied by the dropout probability. Srivastava et al. (2014) showed that this method manages to reduce overfitting significantly while improving the model performance on a range of benchmark problems. Figure 1 depicts a neural network before and after applying dropout.\n",
    "\n",
    "<!--- ![alt text](dropout_nn.png \"Title\")\n",
    "<body>\n",
    "    <div style=\"width:800px; margin:0 auto;\" class=\"image\" style=\"display:table;\">\n",
    "        <img src=\"dropout_nn.png\" alt=\"\" width=\"500\"/>\n",
    "        <div style=\"display:table-caption;\n",
    "                    caption-side:bottom;horizontal-align:middle\">Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.\n",
    "    Dropout: A simple way to prevent neural networks from overfitting. JMLR,\n",
    "    2014.</div>\n",
    "    </div>\n",
    "</body>\n",
    "--->\n",
    "\n",
    "<center><img src=\"dropout_nn.png\" alt=\"\" width=\"500\"></center>\n",
    "      <center>Figure 1: Applying Dropout<br> (Srivastava et al., 2014)</center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!--- continue with ghah2016 who build on srivastava --->\n",
    "Extending the work of Srivastava et al. (2014), Gal and Ghahramani (2016a) show that a neural network of arbitrary depth with dropout applied before every weight layer is mathematically equivalent to an approximate deep Gaussian process. This result provides the theoretical foundation for being able to quantify uncertainty in networks that employ dropout. Notably, they highlight that this approximation can also be interpreted as approximate variational inference in Bayesian neural networks. Furthermore, they introduce MC dropout as a superior alternative to averaging the model weights as done by Srivastava et al. (2014). The main idea of MC dropout is that each random dropout configuration of the neural network asymptotically corresponds to a sample from the approximate parametric posterior distribution. Monte Carlo integration can then be used to infer properties about the distribution. The results of stochastic forward passes through the network are averaged to obtain a prediction, while the predictions themselves approximate the predictive distribution given an input.\n",
    "\n",
    "\n",
    "<!--- actual implementation etc in methodology (including formulas for mean, variance, regularization term) --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mpmPAq4MB3_"
   },
   "source": [
    "### 4. Data <a name=\"data\"></a>\n",
    "\n",
    "In this application, we are using a data set containing borrowers of mortgage loans from a US financial institution. This data set also includes a variable which states whether or not a borrower defaulted on their loan over a three-year horizon. This is the variable we will be trying to predict using our models. The data covers a time period from 2013 to 2016 and nearly 150,000 distinct loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oxaXSAiBMB4A"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessing as pp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp_pqukkMB4E"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/data_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T80TPjFOMB4H"
   },
   "source": [
    "After reading in the data, we first recode the values that indicate missing values following the data set description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGb3eT2-MB4K"
   },
   "outputs": [],
   "source": [
    "data_train = pp.recodeMissing(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TaXda6XMB4M"
   },
   "source": [
    "Next, we reduce the cardinality of the zipcode variable by applying Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlWJMOcBMB4N"
   },
   "outputs": [],
   "source": [
    "data_train = pp.recodeZipcode(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVctnfPhMB4O"
   },
   "source": [
    "Before continuing further, we will remove all redundant features as well as those that we deem to not contain a significant amount of additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_9xmI04MB4P"
   },
   "outputs": [],
   "source": [
    "data_train = pp.removeColumns(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrfPnGOUMB4Q"
   },
   "source": [
    "Finally, we will recode all the dummy variables appropriately in line with the data set description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aI50cu7nMB4R"
   },
   "outputs": [],
   "source": [
    "data_train = pp.recodeDummies(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mTXJjCIMB4S"
   },
   "source": [
    "Now we are ready to split the data into a training and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5amhr4xMB4T"
   },
   "outputs": [],
   "source": [
    "X = data_train.drop(\"TARGET\", axis=1)\n",
    "y = data_train.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhjux8E_MB4V"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G58LdniJMB4X"
   },
   "source": [
    "In both the training and the validation set, we dummy-encode the categorical features. Because we are using at least one neural network that employs weight decay, we will not remove a category from the recoded features. This is because the network would become biased in favor of the omitted category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "099T_SqsMB4Y"
   },
   "outputs": [],
   "source": [
    "X_train = pp.getDummies(X_train)\n",
    "X_val = pp.getDummies(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sijd14yrMB4a"
   },
   "source": [
    "Within both sets, we normalize the continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kuGFGFaMB4b"
   },
   "outputs": [],
   "source": [
    "X_train = pp.normalizeFeatures(X_train)\n",
    "X_val = pp.normalizeFeatures(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWNEqcK3MB4c"
   },
   "source": [
    "Finally, we handle the missing values. For features with only very few missing values, we remove those observations. We identified these features to be the credit score (\"fico\"), the first-time homebuyer flag (\"flag_fthb\"), and the original combined loan-to-value ratio (\"cltv\"). As there are a few variables with a more significant number of missing values, we will impute these values using the k-Nearest Neighbors algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vRxoMRFMB4d",
    "outputId": "ecda6cc0-b3c7-428e-9e9f-7b83a1f4769e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flag_fthb    8\n",
       "fico         8\n",
       "cltv         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[[\"flag_fthb\", \"fico\", \"cltv\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2d2zeOiMB4f"
   },
   "outputs": [],
   "source": [
    "y_train = y_train[~X_train[\"flag_fthb\"].isna() & ~X_train[\"fico\"].isna() & ~X_train[\"cltv\"].isna()]\n",
    "\n",
    "X_train = X_train.dropna(subset=[\"flag_fthb\", \"fico\", \"cltv\"])\n",
    "\n",
    "y_val = y_val[~X_val[\"flag_fthb\"].isna() & ~X_val[\"fico\"].isna() & ~X_val[\"cltv\"].isna()]\n",
    "\n",
    "X_val = X_val.dropna(subset=[\"flag_fthb\", \"fico\", \"cltv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWKUFZ1FMB4g"
   },
   "source": [
    "We will fit the imputer on the training set only in order to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWrAG4jkMB4g"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns = X_train.columns)\n",
    "X_val = pd.DataFrame(imputer.transform(X_val), columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbNN2hQ_MB4h"
   },
   "source": [
    "Lastly, we will compute the initial imbalance ratio of the training set. As we are dealing with a credit risk classification problem, it is natural that the negative class heavily outweighs the positive class, where positive means that a default on the loan occured. To improve the predictive performance, we will resample the training set using Synthetic Minority Over-sampling technique (SMOTE) to create more instances of the positive class before applying random under-sampling to prune the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbRE3swsMB4h",
    "outputId": "0cd7f950-8e8b-4d68-a0f4-0254b2b2b015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio:  110.29\n"
     ]
    }
   ],
   "source": [
    "ir = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "print(\"Imbalance ratio: \", ir.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94H8S31MMB4i"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "cat_features = np.array([1, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
    "\n",
    "smt = SMOTENC(categorical_features=cat_features, sampling_strategy=0.3, random_state=666)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=123,\n",
    "                        sampling_strategy=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bjys411FMB4i"
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('smt', smt), ('rus', rus)])\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FSJW23E61Hw"
   },
   "outputs": [],
   "source": [
    "# save the data sets\n",
    "X_resampled.to_csv(\"data/X_resampled.csv\")\n",
    "y_resampled.to_csv(\"data/y_resampled.csv\")\n",
    "\n",
    "X_val.to_csv(\"data/X_val.csv\")\n",
    "y_val.to_csv(\"data/y_val.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0_UGBGnMB4j"
   },
   "source": [
    "Finally, we verify that the resampling process worked as expected by checking the imbalance ratio of the resampled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1IlhV9DMB4j",
    "outputId": "6c6af401-0eac-4163-e04f-93006c8a5781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio after applying SMOTE and random under-sampling:  3.33\n"
     ]
    }
   ],
   "source": [
    "ir = len(y_resampled)/y_resampled.sum()\n",
    "ir = y_resampled.value_counts()[0] / y_resampled.value_counts()[1]\n",
    "print(\"Imbalance ratio after applying SMOTE and random under-sampling: \", ir.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rBQRpOQMB4k"
   },
   "source": [
    "### 5. Methodology <a name=\"methods\"></a>\n",
    "\n",
    "We will be using two different approaches to quantify uncertainty in neural networks, which we implement in this chapter, namely variational inference and MC dropout. The goal of this section is to compare how these models differ in measuring uncertainty. To facilitate this comparison, we will be using the same network architecture across both models. We will first provide an additional theoretical background concerning the implementation of the two models as well as of how to use them to measure uncertainty in practice before describing their respective actual implementation used in our application.\n",
    "\n",
    "### 5a. Variational Inference for Bayesian Neural Networks <a name=\"bnn\"></a>\n",
    "\n",
    "Traditional learning methods minimize some objective function and obtain point estimates of the optimal parameters. In contrast, Bayesian learning methods output a distribution over probable parameters, indicating their likelihood and thus take into account uncertainty (MacKay 1995).\\\n",
    "As mentioned in Section 3a, the posterior distribution $p(\\omega|\\mathbf{X},\\mathbf{Y})$ is calculated by normalizing the joint distribution over the observed and latent variables, $p(\\mathbf{Y}|\\mathbf{X}, \\omega) p(\\omega)$, by the evidence $p(\\mathbf{Y}|\\mathbf{X})$,\n",
    "which is unknown. Based on Gal and Ghahramani (2016b), we can estimate the evidence as\n",
    "\n",
    "$$p(\\mathbf{Y}|\\mathbf{X})=∫p(\\mathbf{Y}|\\mathbf{X},\\omega)p(\\omega)d\\omega.$$\n",
    "\n",
    "However, this integral is intractable. \n",
    "As a workaround, variational methods find a variational distribution $q^*$ that is part of a predefined family of distributions $Q$ and best fits the true posterior distribution $p(\\omega|\\mathbf{X},\\mathbf{Y})$. In VI, performing approximate posterior inference thus becomes an optimization problem (Blei et al., 2018). The goal is to find a distribution that comes as close to the true posterior as possible, where we measure the distance using the Kullback-Leibler divergence. Based on Gal (2016), the KL divergence is generally computed as\n",
    "\n",
    "$$\\mbox{KL}(q(\\omega)||p(\\omega|\\mathbf{X})) =∫q(\\omega)\\log\\frac{q(\\omega)}{p(\\omega|\\mathbf{X})}d\\omega = -\\int q(\\omega)\\log\\frac{p(\\omega|\\mathbf{X})}{q(\\omega)}d\\omega.$$\n",
    "\n",
    "Here, we would require the true posterior. Instead, we can maximize the evidence lower bound (ELBO), which, up to an added constant, is equivalent to minimizing the KL divergence (Kucukelbir, 2017) and can be written as\n",
    "\n",
    "$$\\mathbb{E}_q[\\log p(\\mathbf{X}|\\omega)]-\\mbox{KL}(q(\\omega)||p(\\omega)).$$\n",
    "\n",
    "Maximizing the first term means selecting those models from the variational family $q \\in Q$ that better predict the data. This also implies that the second term, the negative KL divergence between the variational model and the prior over the latent variables, is pushed towards zero, inferring that the distributions are as similar to each other as possible. \n",
    " \n",
    "Evidently, a crucial step in performing variational inference is specifying the family of distributions from which that member is chosen which best approximates the true posterior. Then, the corresponding objective function needs to be formulated before computing the derivatives and running a gradient-based or coordinate-ascent optimization (Kucukelbir et al., 2016). \n",
    "Using Automatic Differentiation Variational Inference, these computations can be automated. As model output, we not only obtain predictions and point estimates of our weights, but we additionally receive probability distributions for each of the network weights in the model. \n",
    "Following Kucukelbir et al. (2016), the steps of ADVI are as follows:\n",
    "1. ADVI transforms the model into one with unconstrained real-valued latent variables\n",
    "2. ADVI defines the corresponding variational problem on the transformed variables. All latent variables are defined on the same space, so only one single variational family for all models is needed\n",
    "3. ADVI reparameterizes the gradient in terms of a standard Gaussian, thus another transformation is performed, this time within the variational family which enables efficient computation of Monte Carlo approximations, because we only need to sample from a standard Gaussian\n",
    "4. ADVI uses noisy gradients to optimize the variational distribution\n",
    "\n",
    "Consequently, due to the Bayesian nature of the method, uncertainty quantification is directly incorporated into the model and expressed in terms of probability distributions over all unknown parameters. As Neal (1995) points out, the combination of this likelihood function across all parameter values and the predefined prior distribution yields the posterior distribution which conclusively incorporates both the initial belief conveyed by the prior and the observed information from the likelihood. We can learn from this final probability distribution using standard methods from probability theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTA041U2MB4k"
   },
   "source": [
    "#### Implementing the Model\n",
    "\n",
    "Due to computational limitations, we implement the model making use of ADVI in a cloud-based environment. It can be accessed [here](https://colab.research.google.com/github/jsonnenburg/apa_topic5/blob/main/VImodel.ipynb).\n",
    "<!---\n",
    "[![Implementation of ADVI in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://www.google.com/) \n",
    "--->\n",
    "\n",
    "Using this approach, we try to maximize the ELBO which corresponds to minimizing the KL divergence. \n",
    "The plot below shows the negative ELBO track for the 30,000 iterations. We observe that with increasing iterations, the loss converges, indicating that we are able to find an estimated (variational) posterior that is sufficiently similar to the true posterior and enables approximate inference.\n",
    "\n",
    "<center><img src=\"images/elbo_curve.png\" alt=\"\" width=\"1000\"></center>\n",
    "      <center>Figure 2: Negative ELBO track of the Variational Inference Model</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tXYqPLUMB4l"
   },
   "source": [
    "### 5b. Dropout Neural Network <a name=\"dropoutnet\"></a>\n",
    "As explained in Section 3c, Gal and Ghahramani (2016a) show that dropout approximates variational inference in Bayesian neural networks. They find that the dropout objective effectively \"minimizes the Kullback-Leibler divergence between an approximate distribution and the posterior of a deep Gaussian process\" (Gal and Ghahramani, 2016a, p.3). As opposed to the standard way of applying dropout only during training when using it simply as a regularization technique, Gal and Ghahramani (2016a) apply it also at test time to obtain a distributional prediction when performing a specified number of stochastic forward passes through the neural network. We can then compute the empirical estimates of the moments of this approximate predictive distribution. \n",
    "\n",
    "<!--- first and second moment --->\n",
    "\n",
    "If we consider $x^*$ a vector of a single new input and $\\hat{y}^*$ the corresponding vector of outputs of the neural network with length $T$, the number of stochastic forward passes through the network, then we can compute an unbiased estimator of the first moment of the predictive distribution using MC integration as\n",
    "\n",
    "$$\\mathbb{E}_{q(y^*|x^*})(y^*) \\approx \\frac{1}{T}\\sum_{t=1}^{T}\\hat{y}^*(x^*,W^t_1,...,W^t_L),$$\n",
    "\n",
    "with $\\{W^t_1,...,W^t_L\\}^T_{t=1}$ vector sets of realizations from the Bernoulli distribution.\n",
    "\n",
    "Using\n",
    "$$\\mathbb{E}_{q(y^*|x^*)}\\big((y^*)^T(y^*)\\big)\\approx \\tau^{-1}I_D + \\frac{1}{T}\\sum_{t=1}^{T}\\hat{y}^*(x^*,W^t_1,...,W^t_L)^T\\hat{y}^*(x^*,W^t_1,...,W^t_L),$$\n",
    "\n",
    "we can compute the second moment of the predictive distribution similarly as\n",
    "\n",
    "$$\\mbox{Var}_{q(y^*|x^*)(y^*)} \\approx \\mathbb{E}_{q(y^*|x^*)}\\big((y^*)^T(y^*)\\big) - \\mathbb{E}_{q(y^*|x^*)}(y^*)^T\\mathbb{E}_{q(y^*|x^*)}(y^*),$$\n",
    "\n",
    "which is equal to the sample variance computed over the number of stochastic forward passes plus the inverse of the model precision $\\tau$. The first two moments of the approximate predictive distribution will act as an indicator of model uncertainty. Thus, we are able to obtain some quantification of this type of uncertainty by performing stochastic forward passes through the model and collecting the model output for each pass, which are then the approximate predictive distribution. In classification tasks, we can make use of additional measures of uncertainty such as the variation ratio (VR) of the model predictions that is superior to the variance or standard deviation in this setting. For each input, we collect the set of $T$ outputs and find the mode of this output distribution sample as $c^* = \\arg \\max \\sum_{t}\\mathbb{1}[y^t = c]$ together with the number of times it is contained in the sample, $f_x = \\sum_{t}\\mathbb{1}[y^t = c^*]$. Then,\n",
    "\n",
    "$$\\mbox{VR}[x]:= 1 - \\frac{f_x}{T}.$$\n",
    "\n",
    "Gal and Ghahramani (2016a) introduce the VR as a measure of how scattered the distribution of outputs is around the mode. In a binary classification task, the VR attains a maximum of 0.5 in the case of the two classes being contained in the sample from the approximate predictive distribution the same number of times, and a minimum of 0 if the sample contains only a single class.\n",
    "\n",
    "Importantly, measures such as the variance for regression and the entropy or VR for classification problems do not capture a model's confidence in its output but the total uncertainty in the prediction.\n",
    "This uncertainty contains both the variance of the observation error, the aleatoric uncertainty, and the variance due to parameter uncertainty, the epistemic uncertainty (Hüllermeier and Waegeman, 2021).\n",
    "\n",
    "<!--- \n",
    "$$Var_{q(y^*|x^*)(y^*)} \\approx \\mathbb{E}_{q(y^*|x^*)}\\big((y^*)^T(y^*)\\big) - \\mathbb{E}_{q(y^*|x^*)}(y^*)^T\\mathbb{E}_{q(y^*|x^*)}(y^*), \\mbox{ with}$$\n",
    "\n",
    "$$\\mathbb{E}_{q(y^*|x^*)}\\big((y^*)^T(y^*)\\big)\\approx \\tau^{-1}I_D + \\frac{1}{T}\\sum_{t=1}^{T}\\hat{y}^*(x^*,W^t_1,...,W^t_L)^T\\hat{y}^*(x^*,W^t_1,...,W^t_L)$$\n",
    "--->\n",
    "\n",
    "The model precision mentioned above can be calculated as\n",
    "\n",
    "$$\\tau = \\frac{l^2(1-p)}{2N\\lambda},$$\n",
    "\n",
    "where $l$ is the prior length-scale, a value that captures our belief about the model function's frequency, $1-p$ is the dropout rate, $N$ is the number of observations, and $\\lambda$ is the weight decay.\n",
    "\n",
    "We can rewrite this term to\n",
    "\n",
    "$$\\lambda = \\frac{l^2(1-p)}{2N\\tau},$$\n",
    "\n",
    "such that we can later determine the optimal weight decay by optimizing over $p$ and $\\tau$ while holding $l$ constant, as done in Gal and Ghahramani (2016a). \n",
    "\n",
    "A short prior length-scale $l$ will lead to more erratic functions with higher frequencies through input weights of high magnitude. A long prior length-scale will accordingly result in smoother functions and lower magnitude input weights. The combination of a short length-scale with high model precision will lead to a small weight decay, which encourages the model to fit the data well but leads to potential generalization difficulties. A large weight decay follows from pairing a long length-scale with low precision, facilitating the generalization. The trade-off between prior length-scale and model precision results in different values for the weight decay $\\lambda$. This term represents choosing a prior distribution in the given setting, as explained in Gal and Ghahramani (2016a).\n",
    "\n",
    "<!--- log likelihood --->\n",
    "Gal and Ghahramani (2016a) calculate the predictive log-likelihood (LL) by MC integration. The LL will be used to optimize the model parameters $\\tau$ and $p$ via grid-search as it is an indicator of how well the model fits the data. In addition, the LL can also be used to determine the quality of uncertainty. We compute the LL as\n",
    "\n",
    "$$\\log p(y^*|x^*, X, Y) \\approx \\mbox{logsumexp}\\Big(-\\frac{1}{2}\\tau||y-\\hat{y}_t||^2\\Big) - \\log T - \\frac{1}{2}\\log2\\pi-\\frac{1}{2}\\log\\tau^{-1}.$$\n",
    "\n",
    "The last term results in a large penalty if the observation noise is large (i.e. the model precision is low). High model precision but poor mean estimates will result in a large penalty from the first term because the distance between the true and the predicted values gets amplified by $\\tau$.  \n",
    "\n",
    "As described in Gal (2016), we learn both the aleatoric noise and capture the epistemic uncertainty by grid-searching over the dropout probability and the model precision, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSJXDeS_MB4l"
   },
   "source": [
    "#### Implementing the Model\n",
    "In the implementation of the neural network, we will add an $L_2$ regularization term to the hidden layers. As mentioned previously, this corresponds to choosing a prior distribution and is a key component of Bayesian modelling. This prior does not convey concrete information as we have no initial beliefs about the weight distribution.\n",
    "\n",
    "We will additionally add dropout regularization before every weight layer, as specified in Gal and Ghahramani (2016a). Crucially, we will apply dropout at both training and test time as opposed to just during training as is commonly done when using it as a regularization technique. This will allow us to simulate drawing samples from the approximate posterior predictive distribution $q_\\theta(y|x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_FYwVZRMB4m"
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlrOZve5MB4m"
   },
   "source": [
    "Adapting [the code](https://github.com/yaringal/DropoutUncertaintyExps/blob/master/net/net.py) provided by Gal and Gharamani (2016), we first define a class used to initialize the neural network, perform the stochastic forward passes to obtain a distributional prediction as well as to calculate the uncertainty measures, comprising an additional function with which we will calculate the predictive log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTizjTxBMB4n"
   },
   "outputs": [],
   "source": [
    "class net:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, n_hidden, n_epochs = 30, \n",
    "                 tau = 1.0, dropout = 0.05):\n",
    "\n",
    "        \"\"\"\n",
    "            Constructor for the class implementing a Bayesian neural network\n",
    "            trained with the probabilistic back propagation method.\n",
    "\n",
    "            @param X_train      Matrix with the features for the training data.\n",
    "            @param y_train      Vector with the target variables for the\n",
    "                                training data.\n",
    "            @param X_val        Matrix with the features for the validation data.\n",
    "            @param y_val        Vector with the target variables for the \n",
    "                                validation data.\n",
    "            @param n_hidden     Vector with the number of neurons for each\n",
    "                                hidden layer, e.g., [10, 10] for two layers\n",
    "                                with 10 neurons each.\n",
    "            @param n_epochs     Numer of epochs for which to train the\n",
    "                                network.\n",
    "            @param tau          Tau value used for regularization.\n",
    "            @param dropout      Dropout rate for all dropout layers in the\n",
    "                                network.\n",
    "        \"\"\"\n",
    "\n",
    "        X_train = np.array(X_train, ndmin = 2)\n",
    "        y_train = np.array(y_train, ndmin = 2)\n",
    "        \n",
    "        # network params\n",
    "        N = X_train.shape[0]\n",
    "        batch_size = 128\n",
    "        lengthscale = 1e-2\n",
    "        reg = lengthscale**2 * (1 - dropout) / (2. * N * tau) \n",
    "        \n",
    "        # network construction\n",
    "        inputs = Input(shape=(X_train.shape[1],))\n",
    "        inter = Dropout(dropout)(inputs, training=True)\n",
    "        inter = Dense(n_hidden[0], activation='relu', kernel_initializer=keras.initializers.he_normal(seed=123), kernel_regularizer=l2(reg))(inter)\n",
    "        for i in range(len(n_hidden) - 1):\n",
    "            inter = Dropout(dropout)(inter, training=True)\n",
    "            inter = Dense(n_hidden[i+1], activation='relu', kernel_initializer=keras.initializers.he_normal(seed=123), kernel_regularizer=l2(reg))(inter)\n",
    "        inter = Dropout(dropout)(inter, training=True)\n",
    "        outputs = Dense(y_train.shape[1], activation='sigmoid', kernel_initializer=keras.initializers.he_normal(seed=123), kernel_regularizer=l2(reg))(inter)\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, validation_data=(X_val, y_val), verbose=0)\n",
    "        \n",
    "        # meta info params\n",
    "        self.running_time = time.time() - start_time\n",
    "        self.model = model\n",
    "        self.tau = tau\n",
    "        self.VR = None\n",
    "        self.Yt_hat = None\n",
    "        self.test_time = None\n",
    "\n",
    "    def predict(self, X_test, T = 100):\n",
    "\n",
    "        \"\"\"\n",
    "            Function for making predictions with the Bayesian neural network.\n",
    "\n",
    "            @param X_test   The matrix of features for the test data.\n",
    "            @param y_test   The matrix of labels for the test data.\n",
    "            @param T        The number of Monte Carlo trials.\n",
    "            \n",
    "            @return MC_pred The predictive mean for the test target variables.\n",
    "            @return \n",
    "            standard_pred   An array of predictions for the test target, \n",
    "                            computed from a single forward pass.\n",
    "        \"\"\"\n",
    "\n",
    "        model = self.model\n",
    "        \n",
    "        # obtain single prediction\n",
    "        standard_pred = model.predict(X_test, batch_size=500, verbose=0)\n",
    "        \n",
    "        self.T = T\n",
    "        \n",
    "        # obtain MC predictions\n",
    "        start_time = time.time()\n",
    "        preds = [model(X_test, training=True) for _ in range(T)]\n",
    "        end_time = time.time()\n",
    "        Yt_hat = np.hstack(preds)\n",
    "\n",
    "        # calculate mean\n",
    "        MC_pred = np.mean(Yt_hat, 1)\n",
    "        \n",
    "        # calculate variation ratio\n",
    "        MC_mode = stats.mode(Yt_hat.round(), 1)[0] # c*\n",
    "        fx = np.array([np.count_nonzero(Yt_hat.round()[i] == MC_mode[i]) for i in range(MC_mode.shape[0])]) # f_x\n",
    "        VR = np.subtract(np.ones(fx.shape[0]), np.divide(fx, T))\n",
    "        \n",
    "        # save meta params\n",
    "        self.VR = VR\n",
    "        self.Yt_hat = Yt_hat\n",
    "        self.test_time = end_time - start_time\n",
    "        \n",
    "        return  MC_pred, standard_pred\n",
    "    \n",
    "    def logLik(self, y_test):\n",
    "        \n",
    "        \"\"\"\n",
    "            Function for computing the predictive log-likelihood.\n",
    "            \n",
    "            @param y_test    The matrix of labels for the test data.\n",
    "            \n",
    "            @return test_ll  The predictive log-likelihood.\n",
    "        \"\"\"\n",
    "        \n",
    "        y_test = np.array(y_test, ndmin = 2)\n",
    "        \n",
    "        ll = (logsumexp(-0.5 * self.tau * (y_test[None] - self.Yt_hat)**2., 0) - np.log(self.T) \n",
    "            - 0.5*np.log(2*np.pi) + 0.5*np.log(self.tau))\n",
    "        \n",
    "        test_ll = np.mean(ll)\n",
    "        \n",
    "        return test_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEZOejSxMB4q"
   },
   "source": [
    "#### Grid-Searching the Optimal Parameters\n",
    "\n",
    "As done similarly in Gal and Gharamani (2016), we will perform grid-search over the LL to find the optimal values for the model precision $\\tau$ and the dropout probability. Here, larger values for the LL signify a better fit to the data. Gal (2016) point out several considerations for choosing $\\tau$ and the dropout rate in practice. Notably, larger models require a higher dropout probability, typically close to 0.5. For a fixed model size, smaller dropout probabilities will result in decreasing predictive uncertainty. If both the model precision and the amount of data are large, the model will be prone to overfitting. This results from giving the expected LL a higher weight than the prior KL divergence (Gal 2016). The length-scale $l$ will be constant so that the optimal weight decay $\\lambda^*$ will depend only on two parameters.\n",
    "\n",
    "<!---\n",
    "- considerations for tau in practice (following gal2016):\n",
    "    - larger models require larger dropout prob. (large models: close to 0.5)\n",
    "    - for fixed model size, smaller dropout probabilities result in decreasing predictive uncertainty\n",
    "    - large tau (high model precision) and large N (large amount of data) give expected LL a higher weight than the prior KL, makes model prone to overfitting\n",
    "    - long prior length-scale results in heavily regularized models that are prone to underfitting\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_88Z18rMB4s"
   },
   "outputs": [],
   "source": [
    "y_resampled = y_resampled.values.reshape(-1, 1)\n",
    "y_val = y_val.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6EuZXkYMB4s"
   },
   "source": [
    "Our neural network will be quite small, with only two hidden layers and a limited number of units in each layer, as we use it only for illustrative purposes. Following Gal (2016), we should opt for a smaller dropout probability given just the size of our network. However, the amount of data we will use for training the network is quite large. Hence, we will start the range of possible dropout rates used in the grid-search at a relatively high value. This will prevent the model from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdB1_HAmMB4t",
    "outputId": "cb3b8f97-3fd1-4e14-d683-986188928963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Grid-search step: tau at 1.0 and dropout rate at 0.15.\n",
      "Best log-likelihood changed to: -5.5563\n",
      "Best tau changed to: 1.0\n",
      "Best dropout rate changed to: 0.15\n",
      "=== Grid-search step: tau at 1.5 and dropout rate at 0.15.\n",
      "Best log-likelihood changed to: -5.3722\n",
      "Best tau changed to: 1.5\n",
      "Best dropout rate changed to: 0.15\n",
      "=== Grid-search step: tau at 2.0 and dropout rate at 0.15.\n",
      "Best log-likelihood changed to: -5.2436\n",
      "Best tau changed to: 2.0\n",
      "Best dropout rate changed to: 0.15\n",
      "=== Grid-search step: tau at 2.5 and dropout rate at 0.15.\n",
      "Best log-likelihood changed to: -5.1473\n",
      "Best tau changed to: 2.5\n",
      "Best dropout rate changed to: 0.15\n",
      "=== Grid-search step: tau at 3.0 and dropout rate at 0.15.\n",
      "Best log-likelihood changed to: -5.0776\n",
      "Best tau changed to: 3.0\n",
      "Best dropout rate changed to: 0.15\n",
      "=== Grid-search step: tau at 3.5 and dropout rate at 0.15.\n",
      "Best log-likelihood changed to: -5.0056\n",
      "Best tau changed to: 3.5\n",
      "Best dropout rate changed to: 0.15\n",
      "=== Grid-search step: tau at 1.0 and dropout rate at 0.2.\n",
      "=== Grid-search step: tau at 1.5 and dropout rate at 0.2.\n",
      "=== Grid-search step: tau at 2.0 and dropout rate at 0.2.\n",
      "=== Grid-search step: tau at 2.5 and dropout rate at 0.2.\n",
      "=== Grid-search step: tau at 3.0 and dropout rate at 0.2.\n",
      "=== Grid-search step: tau at 3.5 and dropout rate at 0.2.\n",
      "=== Grid-search step: tau at 1.0 and dropout rate at 0.25.\n",
      "=== Grid-search step: tau at 1.5 and dropout rate at 0.25.\n",
      "=== Grid-search step: tau at 2.0 and dropout rate at 0.25.\n",
      "=== Grid-search step: tau at 2.5 and dropout rate at 0.25.\n",
      "=== Grid-search step: tau at 3.0 and dropout rate at 0.25.\n",
      "=== Grid-search step: tau at 3.5 and dropout rate at 0.25.\n"
     ]
    }
   ],
   "source": [
    "# list of values for hyperparameters\n",
    "dropout_rates = list([0.15, 0.2, 0.25])\n",
    "tau_values = list([1.0, 1.5, 2.0, 2.5, 3.0, 3.5])\n",
    "\n",
    "# perform grid-search to select the best hyperparameters based on the highest log-likelihood value\n",
    "best_network = None\n",
    "best_ll = -float('inf')\n",
    "best_tau = 0\n",
    "best_dropout = 0\n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "    for tau in tau_values:\n",
    "        print ('=== Grid-search step: tau at ' + str(tau) + ' and dropout rate at ' + str(dropout_rate) + '.')\n",
    "        network = net(X_resampled, y_resampled, X_val, y_val, n_hidden = [64, 32],\n",
    "                      n_epochs = 15, tau = tau, dropout = dropout_rate)\n",
    "\n",
    "        _, _ = network.predict(X_val)\n",
    "        \n",
    "        # compute test log-likelihood on the validation set\n",
    "        ll = network.logLik(y_val) \n",
    "        if (ll > best_ll): \n",
    "            best_ll = ll\n",
    "            best_network = network\n",
    "            best_tau = tau\n",
    "            best_dropout = dropout_rate\n",
    "            print ('Best log-likelihood changed to: ' + str(best_ll.round(4)))\n",
    "            print ('Best tau changed to: ' + str(best_tau))\n",
    "            print ('Best dropout rate changed to: ' + str(best_dropout))\n",
    "\n",
    "# store best results\n",
    "best_network = net(X_resampled, y_resampled, X_val, y_val, n_hidden = [64, 32],\n",
    "                n_epochs = 20, tau = best_tau, dropout = best_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9N3akSgMB4t"
   },
   "source": [
    "### 6. Results <a name=\"results\"></a>\n",
    "In this chapter, we will first evaluate both models' performance on the validation set before exploring how the two models differ in their predictive uncertainty. Furthermore, we will illustrate the options each approach gives us to visualize and quantify the model uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3mD2twmMB4u"
   },
   "source": [
    "#### ADVI Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQtu2ynCMB4u"
   },
   "source": [
    "To evaluate the general predictive performance of the model, we perform a posterior predictive check by sampling from the estimated posterior. Essentially, we generate data from our model and analyze how much that data deviates from the true posterior distribution. We then perform predictions for each observation in the validation set and assess the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0o3t1t32MB4u"
   },
   "outputs": [],
   "source": [
    "# for illustration - do not run\n",
    "with neural_network:\n",
    "    inference = inference\n",
    "    train_trace = pm.sample_approx(approx, draws=100000, include_transformed=True)\n",
    "    pm.set_data(new_data={\"ann_input\": X_val, \"ann_output\": y_val})\n",
    "    ppc = pm.sample_posterior_predictive(train_trace, samples=50000, progressbar=True)\n",
    "    VI_pred = ppc[\"out\"].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HjwcSeTMB4v"
   },
   "source": [
    "We will first assess the general predictive performance of the model using a range of appropriate standard metrics. These include the AUC, as well as precision, recall, and the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "91CDdsjmMB4v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.891 \n",
      "Recall:    0.161 \n",
      "F1-Score:   0.272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import the saved predictions\n",
    "VI_pred_class = pd.read_csv(\"data/classes.csv\").astype(int)\n",
    "y_val = pd.read_csv('data/y_val.csv')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_val['TARGET'], VI_pred_class['0']).ravel()\n",
    "\n",
    "recall = tp / (tp+fn)\n",
    "prec = tn / (tn+fp)\n",
    "f1 = 2*(prec*recall)/(prec+recall)\n",
    "\n",
    "print(\"Precision: \", prec.round(3), \"\\nRecall:   \", recall.round(3), \"\\nF1-Score:  \", f1.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jUn_gfRMB4v"
   },
   "source": [
    "With a BNN, we are also able to evaluate the standard deviation of the estimated posterior of the network weights to get an idea of the uncertainty within the network by examining their distribution, as depicted in Figure 3.\n",
    "\n",
    "<center><img src=\"images/advi_weights.jpg\" alt=\"\" width=\"350\"></center>\n",
    "      <center>Figure 3: Approximate Posterior Predictive Distribution of the Network Weights</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTsuF96sMB4w"
   },
   "source": [
    "Lastly, we can also look at the posterior densities in more detail. Specifically, we can plot the highest density interval (HDI) for each of the network weights, as done in Figure 4.\n",
    "Based on Lu et al. (2012), a credible interval for a variable $X$ can be defined as $Prob (l\\leq X\\leq u)=1-\\alpha$, where $l$ and $u$ are the lower and upper interval limits, $\\alpha$ is the significance level and $1-\\alpha$ is the confidence level. \n",
    "From a Bayesian viewpoint, the prediction is a random variable and a 94% credible interval is expected to include 94% of the probability distribution function of the prediction. In the case of the HDI, a 94% HDI includes all values of $x$ for which the density is as big as some value $W$, such that the integral over all those $x$-values is 94\\%. Thus, the wider the distribution, the more uncertain we are about the true value of the parameter. \n",
    "\n",
    "<center><img src=\"images/HDI.png\" alt=\"\" width=\"900\"></center>\n",
    "      <center>Figure 4: Highest Density Intervals for Some Network Weights</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExY_UULjMB4w"
   },
   "source": [
    "#### Dropout Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3euiYMieMB4x"
   },
   "outputs": [],
   "source": [
    "MC_pred, standard_pred = best_network.predict(X_val, T=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFgNLCYMMB4x"
   },
   "source": [
    "We evaluate the model utilizing the same metrics as used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feRrthySMB4x",
    "outputId": "a593bb18-e255-48eb-8816-eb82e739e6a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of best network: 0.731\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, MC_pred)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"AUC of best network: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBcM-LaHMB4y"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, MC_pred.round()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxfkIFs5MB4y",
    "outputId": "c9b1a9b6-4ddd-4ebf-f404-2ae51ec07912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.936 \n",
      "Recall:    0.208 \n",
      "F1-Score:   0.34\n"
     ]
    }
   ],
   "source": [
    "recall = tp / (tp+fn)\n",
    "prec = tn / (tn+fp)\n",
    "f1 = 2*(prec*recall)/(prec+recall)\n",
    "\n",
    "print(\"Precision: \", prec.round(3), \"\\nRecall:   \", recall.round(3), \"\\nF1-Score:  \", f1.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4ogyx4gMB4z"
   },
   "source": [
    "To provide an idea of what the approximate posterior predictive distribution looks like for individual inputs, we visualize the output distribution together with the MC mean prediction and the prediction of a standard network that applies dropout only at training time for three randomly picked observations. The posterior probability distribution reflects the epistemic uncertainty in a Bayesian setting. The less peaked this distribution is, the less informed the learner is and the higher its epistemic uncertainty (Hüllermeier and Waegeman, 2021). We also depict the distribution of the variation ratio across all outputs. \n",
    "\n",
    "Generally, we expect inputs near the training data to have a smaller epistemic uncertainty component, while inputs far away from the training data will result in higher epistemic uncertainty. Similarly, some parts of the input space might have higher aleatoric uncertainty associated with them than others. These inputs will produce a larger measurement error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vADwyE25MB4z"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(99)\n",
    "\n",
    "idx = random.sample(range(len(X_val)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KwCFw7DMB4z",
    "outputId": "5e810cc6-b961-43fe-8bb6-034bdfb59a85"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAGQCAYAAACqHO27AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABlpElEQVR4nO3dd5ycZbn/8e89ZXe2ZPumb3rZ9E4SICTSmyACIopSBPR4UPB3LCgWjmI5igp4PCgWQEVAEUGCBQRDSYAUSCO9957tO7tT7t8fM4mbsEm2zMzzPLuf9+uV1+7OPOWaduW55m7GWisAAAAAANzG53QAAAAAAAC0hoIVAAAAAOBKFKwAAAAAAFeiYAUAAAAAuBIFKwAAAADAlShYAQAAAACuRMEKAB5ljLnBGPN6i7+tMWaYkzGdiDHmZ8aYrzlw3v8wxuw1xtQZY0ozfO4txphzk79/xRjzyw4e511jzJxUxubEuY0xHzXGvNDi75S+X5Ov8ZBUHQ8A4A4UrADgIS2LoDQd/xFjzD2dPMYxhbQkWWs/Za39Vueia3ccQUk/knS+tTbfWnvwuPsHJYumuuS/LcaYO9MRi7X2O9bam9sQ83uef2vtGGvtvFTG08pj32uMmWuMOa+9525xrMDJtrPWPmatPT8F4csYM88Yc8zzmXyNN6Xi+AAA96BgBQC02amKEpfpJSkk6d1TbFdkrc2XdK2krxtjLjx+A4897vY48tgnSHpR0p+NMTek+iRd+PkDAKQZBSsAdEHHt0C1bPU0CT82xuwzxlQbY5YbY8YaY26V9FFJX0y2uj2X3H6LMeZLxpjlkuqNMQFjzJ3GmI3GmFpjzCpjzBXJbUdJ+pmkmcljVCVvP6bl0BhzizFmgzHmkDHmL8aYvi3us8aYTxlj1htjDhtjfmqMMSd4nNnGmPuMMbuS/+5L3jZC0trkZlXGmJdP9ZxZa99Qorgda4yZY4zZkXzceyQ9bIzxtXjcB40xfzDGlLSI5WPGmK3J++46Ls67jTG/a/H3mcaYBcaYKmPM9uTrc7Ln/1xjTF9jTONx55xkjDmQbE2WMeYmY8zq5PP2D2PMwFM97uRj32OtvV/S3ZL+xxjja3nu5O+nGWMWG2Nqki2yP0ru/mqL57nOGDMz+XjmJ99nhyTdbVppeZd0sTFmU/Ix/KDFeY9/vo624hpjvi1plqT/TZ7vf5PbHO1ibIwpNMb8xhizP/mafLXFsW8wxrxujLk3+TxtNsZc1JbnCQCQeRSsAND9nC/pLEkjJBVJukbSQWvtQ5Iek/T9ZPfK97fY51pJlyjRIheVtFGJoqFQ0n9L+p0xpo+1drWkT0l6I3mMouNPbow5W9J3JX1IUh9JWyU9cdxml0qapkTL34ckXXCCx3KXpBmSJia3PU3SV6216ySNSW5TZK09+2RPiEk4I7nPO8mbe0sqkTRQ0q2SPivpA5JmS+or6bCknyb3Hy3pQUkfS95XKqn/Cc41QNLfJP1EUnky9qWneP5lrd0l6Q1JV7a4+SOSnrLWRowxH5D0FUkfTB73NUmPn+xxt+JpST0ljWzlvvsl3W+tLZA0VNIfkreflfxZlIz7jeTf0yVtSh7v2yc43xWSpkqaLOlySTedKkBr7V1KPLbbkue7rZXNfqLEe3OIEq/XxyXd2OL+6Up8oVEm6fuSfnWiL0UAAM6iYAWA7iciqYekSknGWrvaWrv7FPs8YK3dbq1tlCRr7R+ttbustXFr7ZOS1itRLLbFRyX92lr7trW2SdKXlWiRHdRim+9Za6ustdsk/UuJou5Ex/qmtXaftXa/EsXzx9oYxxEHJB2S9EtJd1prX0reHpf0DWttU/Jxf1LSXdbaHcm475Z0lUl0d71K0lxr7avJ+76W3P9EMf/TWvu4tTZirT1orV3axlh/r8SXB0oWWB9O3qZkfN9Nvp5RSd+RNLGtraxJu5I/S1q5LyJpmDGmzFpbZ61981THstb+xFobPfK+acX/WGsPJV/n+5R8bJ1hjPEr8SXMl621tdbaLZJ+qGPfF1uttb+w1sYkParEFye9OntuAEDqUbACQDdjrX1Z0v8q0Tq41xjzkDGm4BS7bW/5hzHm48aYpckurVWSxirRWtUWfZVoVT0ST52kg5L6tdhmT4vfGyTlt+VYyd/7nmDbEymz1hZba0dZax9ocft+a224xd8DlRjjeeQxr5YUU6LQ6asWz5G1tl6Jx9SaCiVaqDviKSWK+75KtGxaJVobj8R3f4v4DkkyOvZ5PZUj2x5q5b5PKNEqv8YYs8gYc+kpjrX9FPcfv01HXrvWlEnK0nvfF62+v6y1DclfT/QeAwA4iIIVALqmekm5Lf7u3fJOa+0D1topSnSBHSHpC0fuOsHxjt6ebLH7haTbJJUmu/2uVKI4OtkxjtilRHF15Hh5SnSh3XmK/U55LEkD9O9Wws46/nFsl3SRtbaoxb+QtXanpN1KFKKSJGNMrhKPqTXblehS25ZzHnuntVWSXlCim/RHJD1urT2yz3ZJnzwuvhxr7YKTHfM4V0jap3+P/2157vXW2muV6OL7P5KeSr52p3zPnERFi99bvnYnff+e4tgHlGgNPv590ZH3FwDAYRSsANA1LZX0QWNMbnIimk8cucMYM80YMz05UU+9pLASLYWStFeJcX8nc6RI2Z883o1KtLAesVdSf2NM1gn2/72kG40xE40x2Up0XX0r2XWzvR6X9FVjTLkxpkzS1yX97hT7dNTPJH37SBfb5DkvT973lKRLk5MpZUn6pk78f+xjks41xnwoOYlQqTFmYvK+tjz/v1diTOaV+nd34CPxfdkYMyYZX6Ex5uq2PDBjTC9jzG2SvqFEV9r3dGc2xlxnjClP3leVvDmmxPsg3oa4W/MFY0yxMaZC0u2SnkzevlTSWcaYAcaYQiW6jbd0wucp2c33D0q8Vj2Sr9f/U/reFwCANKJgBYCu6ceSmpW4sH9UiSLpiAIlWkgPK9FV8qCke5P3/UrS6GS30mdaO7C1dpUSYwLfSB5/nKT5LTZ5WYnZdvcYYw60sv9LSozx/JMSLZNDlRiL2RH3SFosabmkFZLeTt6WDvdL+oukF4wxtZLeVGLyHllr35X0n0oUkLuVeG53tHaQ5HjNiyX9lxJdb5cqMWGU1IbnPxnDcEl7rbXLWhz3z0q0fD5hjKlRotX7VLPfVhlj6pV47i6WdLW19tcn2PZCSe8aY+qUeC4+bK0NJ7vUflvS/GTcM05xzpaelbREiefgeSUev6y1LypRvC5P3j/3uP3uV2L88GFjzAN6r88o8WXMJkmvK/G6nOhxAQBczPy7JxEAAAAAAO5BCysAAAAAwJUoWAEAAAAArkTBCgAAAABwJQpWAAAAAIArUbACAAAAAFyJghUAAAAA4EoUrAAAAAAAV6JgBQAAAAC4EgUrAAAAAMCVKFgBAAAAAK5EwQoAAAAAcCUKVgAAAACAK1GwAgAAAABciYIVAAAAAOBKFKwAAAAAAFeiYAUAAAAAuBIFKwAAAADAlShYAQAAAACuRMEKAAAAAHAlClYAAAAAgCtRsAIAAAAAXImCFQAAAADgShSsAAAAAABXomAFAAAAALgSBSsAAAAAwJUoWAEAAAAArkTBCgAAAABwJQpWAAAAAIArpa1gNcb82hizzxizssVtJcaYF40x65M/i9N1fgDIBHIdgO6CfAfACelsYX1E0oXH3XanpJestcMlvZT8GwC87BGR6wB0D4+IfAcgw4y1Nn0HN2aQpLnW2rHJv9dKmmOt3W2M6SNpnrV2ZNoCAIAMINcB6C7IdwAyLdNjWHtZa3dLUvJnzwyfHwAygVwHoLsg3wFIq4DTAZyIMeZWSbdKUl5e3pTKykqHI0JHrV2b+DmS71tPjSerXZYsWXLAWlvudByd0elc14H3DG8zwFvIdeiMbpnzu+WD9r4T5bpMF6x7jTF9WnQb2XeiDa21D0l6SJKmTp1qFy9enKkYkWJz5iR+zpvnZBQewZPVLsaYrU7HcAKZy3UdeM/wNgO8xcW5TmpjvuO6zjndMud3ywftfSfKdZnuEvwXSdcnf79e0rMZPj8AZAK5DkB3Qb4DkFbpXNbmcUlvSBppjNlhjPmEpO9JOs8Ys17Secm/AcCzyHUAugvyHQAnpK1LsLX22hPcdU66zgkAmUauA9BdkO8AOMG1ky6h+4hEItqxY4fC4bDToTjvG99I/Fy92tk4XCYUCql///4KBoNOh+JKVtLVDy7Qj6+ZqIqSXKfDAQAASBkKVjhux44d6tGjhwYNGiRjjNPhOMuX7KXPrHZHWWt18OBB7dixQ4MHD3Y6HFcKR2JavPWwvvrMSj1y4zQ+RwAAoMvI9KRLwHuEw2GVlpZykY1WGWNUWlpKC/xJNDTHNGVgsVbtrtH6fXVOhwMAAJAyFKxwBYpVnAzvj5Orb4pqUGmuBpTkatvBBqfDAQAASBkKVkCJguhjH/vY0b+j0ajKy8t16aWXHr3tb3/7m6ZOnapRo0apsrJSn//8550INWPmzZt3zOOHe9U3xzSwJE+leVnaVd3odDgAAAApQ8EKSMrLy9PKlSvV2Ji42H/xxRfVr1+/o/evXLlSt912m373u99p9erVWrlypYYMGeJUuJ0Si8WcDgEp1tAU1YDSXJXkZWn7IQpWAADQdVCwAkkXXXSRnn/+eUnS448/rmuv/ffs/d///vd11113qbKyUpIUCAT06U9/+j3HuPvuu3X99dfr/PPP16BBg/T000/ri1/8osaNG6cLL7xQkUhEkrRkyRLNnj1bU6ZM0QUXXKDdu3dLkn7xhz9o2lVXacKECbryyivV0JDo3nnDDTfos5/9rE4//XQNGTJETz311HvOvWXLFlVWVur666/X+PHjddVVVx3df9CgQfrmN7+pM888U3/84x/1wgsvaObMmZo8ebKuvvpq1dUlxj3+/e9/V2Vlpc4880w9/fTTqXpqkUbRuFUsblXeI1tl+dnafpguwQAAoOugYIWr3HGHNGdOav/dcUfbzv3hD39YTzzxhMLhsJYvX67p06cfvW/lypWaMmVKm46zceNGPf/883r22Wd13XXX6X3ve59WrFihnJwcPf/884pEIvrMZz6jp556SkuWLNFNN92ku+66S5L0wfPO06KnntKyZcs0atQo/epXvzp63N27d+v111/X3Llzdeedd7Z67rVr1+rWW2/V8uXLVVBQoP/7v/87el8oFNLrr7+uc889V/fcc4/++c9/6u2339bUqVP1ox/9SOFwWLfccouee+45vfbaa9qzZ0/bnjg4qjkaVzDgk88YlffI1s7DtLACAICug2VtgKTx48dry5Ytevzxx3XxxRd3+DgXXXSRgsGgxo0bp1gspgsvvFCSNG7cOG3ZskVr167VypUrdd5550lKdNHt06ePJGnl+vX66v33q6qpSXV1dbrggguOHvcDH/iAfD6fRo8erb1797Z67oqKCp1xxhmSpOuuu04PPPDA0bG211xzjSTpzTff1KpVq45u19zcrJkzZ2rNmjUaPHiwhg8ffnT/hx56qMPPAzIjGo/L70tMSlWWn61dVRSsAACg66Bghavcd5+z57/sssv0+c9/XvPmzdPBgweP3j5mzBgtWbJEEyZMOOUxsrOzJUk+n0/BYPDoDLc+n0/RaFTWWo0ZM0ZvvPHGe/a94ctf1jM//akmXH65HnnkEc2bN+89x5USa5O25vjZdFv+nZeXd3Tf8847T48//vgx2y5dupTZeD0oErMKJAvWotygasIRhSMxhYJ+hyMDAADoPLoEAy3cdNNN+vrXv65x48Ydc/sXvvAFfec739G6deskSfF4XD/60Y86dI6RI0dq//79RwvWSCSid999V5JUW1+vPuXlikQieuyxx9p97G3bth097uOPP64zzzzzPdvMmDFD8+fP14YNGyRJDQ0NWrdunSorK7V582Zt3Ljx6P5wv2js3y2sPmNUmp+t3dWsWQsAALoGClaghf79++v2229/z+3jx4/Xfffdp2uvvVajRo3S2LFjj06U1F5ZWVl66qmn9KUvfUkTJkzQxIkTtWDBAknSt26/XdM/9CGdd955Ryd4ao9Ro0bp0Ucf1fjx43Xo0CH9x3/8x3u2KS8v1yOPPKJrr71W48eP14wZM7RmzRqFQiE99NBDuuSSS3TmmWdq4MCBR/dZvHixbr755g49XqRXJGblb9EyXp7POFYAANB1mBN1LXSTqVOn2sWLFzsdBjpozpzEzxa9W4+xevVqjRo1KlPhuNvatYmfI0e2e9ctW7bo0ksv1cqVK1MclDu09j4xxiyx1k51KKSU60iu2zx2miRpz7N/lyT977/W65ppA3TZhL4n3OdUn0kA7kKuQ2d0y5zfLR+0950o19HCCgAeFmnRJViS8rICqm5odjAiAACA1KFgBbqIQYMGddnWVZxYNP7vSZckKS87oMMNEQcjAgAASB0KVgDwsEQL679TeV5WQIfqaWEFAABdAwUrAHhYNHZsC2t+yK/DdAkGAABdBAUrAHiUtVbRuJXf36JgzQ6qii7BAACgi6BgBQCPqm2KyhjJtLgtPzugKlpYAQBAF0HBCkj69re/rTFjxmj8+PGaOHGi3nrrLUnSzTffrFWrVnXomFu2bNHYsWM7HNPdd9+te++9t8P7d8aWLVv0+9//PiPneuSRR3Tbbbdl5FxdzaG65mO6A0vJgrWRFlYAANA1BJwOAHDaG2+8oblz5+rtt99Wdna2Dhw4oObmRAvVL3/5S4eje69oNKpAIL0f3SMF60c+8pEOHyMWi8nv96cwKhzvUEPzMUvaSFJ+KKAaClYAANBF0MKKbm/37t0qKytTdna2JKmsrEx9+/aVJM2ZM0dHFjfPz8/XXXfdpQkTJmjGjBnau3evJGnjxo2aMWOGpk2bpq9//evKz89/zzlisZi+8IUvaNq0aRo/frx+/vOftxrLt3/2M4288EKde+65Wrt27dHb58yZo6985SuaPXu27r//fr300kuaNGmSxo0bp5tuuklNTU2SEkvbfOlLX9Jpp52m0047TRs2bJAkbd26Veecc47Gjx+vc845R9u2bZMk3XDDDXrqqaeOnudI7Hfeeadee+01TZw4UT/+8Y+PiXHevHk666yzdMUVV2j06NH61Kc+pXg8fnT/r3/965o+fbreeOMN/e53v9Npp52miRMn6pOf/KRisZgk6eGHH9aIESM0e/ZszZ8/v82vFY5VF47Kb44tWPOy/aoJR2WtdSgqAACA1KFghbvccYc0Z05q/91xx0lPef7552v79u0aMWKEPv3pT+uVV15pdbv6+nrNmDFDy5Yt01lnnaVf/OIXkqTbb79dt99+uxYtWnS00D3er371KxUWFmrRokVatGiRfvGLX2jz5s3HbLNkyRI98fzzeufPf9bTTz+tRYsWHXN/VVWVXnnlFf3nf/6nbrjhBj355JNasWKFotGoHnzwwaPbFRQUaOHChbrtttt0R/Kx33bbbfr4xz+u5cuX66Mf/ag++9nPnvQ5+d73vqdZs2Zp6dKl+tznPvee+xcuXKgf/vCHWrFihTZu3Kinn3766HM0duxYvfXWWyotLdWTTz6p+fPna+nSpfL7/Xrssce0e/dufeMb39D8+fP14osvdrjLNaS6pqh8x7WwBnw+ZQd8qm2KOhQVAABA6lCwotvLz8/XkiVL9NBDD6m8vFzXXHONHnnkkfdsl5WVpUsvvVSSNGXKFG3ZskVSokvx1VdfLUkn7EL7wgsv6De/+Y0mTpyo6dOn6+DBg1q/fv0x27z22mu64rzzlJuTo4KCAl122WXH3H/NNddIktauXavBgwdrxIgRkqTrr79er7766tHtrr322qM/33jjjaMxHontYx/7mF5//fU2Pz+tOe200zRkyBD5/X5de+21R4/n9/t15ZVXSpJeeuklLVmyRNOmTdPEiRP10ksvadOmTXrrrbc0Z84clZeXKysr6+jjQvvVhaPyHdfCKkkFoaCqmSkYAAB0AYxhhbvcd58jp/X7/ZozZ47mzJmjcePG6dFHH9UNN9xwzDbBYFAmWRz4/X5Fo21vwbLW6ic/+YkuuOCCk2733tLj3/Ly8o4e66THaFHAmFaKmZa3BwKBo915rbVHx+6eyvHHPfJ3KBQ6Om7VWqvrr79e3/3ud4/Z9plnnjlhXGif2qaofK08lfmhgKoaIqooyXxMAAAAqUQLK7q9tWvXHtPauXTpUg0cOLDN+8+YMUN/+tOfJElPPPFEq9tccMEFevDBBxWJJFq91q1bp/r6+mO2Oeuss/Tnf/5TjeGwamtr9dxzz7V6rMrKSm3ZsuXo+NTf/va3mj179tH7n3zyyaM/Z86cKUk6/fTTj8b22GOP6cwzz5SUGPO6ZMkSSdKzzz57NL4ePXqotrb2hI954cKF2rx5s+LxuJ588smjx2vpnHPO0VNPPaV9+/ZJkg4dOqStW7dq+vTpmjdvng4ePKhIJKI//vGPJzwPTq4u/N4uwVJipuDDLG0DAAC6AFpY0e3V1dXpM5/5jKqqqhQIBDRs2DA99NBDbd7/vvvu03XXXacf/vCHuuSSS1RYWPiebW6++WZt2bJFkydPlrVW5eXleuaZZ47ZZvLkybrm4os18QMf0MDhwzVr1qxWzxcKhfTwww/r6quvVjQa1bRp0/SpT33q6P1NTU2aPn264vG4Hn/8cUnSAw88oJtuukk/+MEPVF5erocffliSdMstt+jyyy/XaaedpnPOOedoK+748eMVCAQ0YcIE3XDDDe8Zxzpz5kzdeeedWrFixdEJmI43evRo3XPPPTr//PMVj8cVDAb105/+VDNmzNDdd9+tmTNnqk+fPpo8efLRyZj+8pe/aPHixfrmN7/Zxme/e6sJR1rtEpyX7WdpGwAA0CUYL8wkOXXqVHtkplZ4z5w5iZ/z5rV+/+rVqzVq1KhMhZNyDQ0NysnJkTFGTzzxhB5//HE9++yzHTvYkZmBR47s0O6DBg3S4sWLVVZW1rHzt8G8efN07733au7cuWk7R2tae58YY5ZYa6dmNJA0am+u++JTy/Xp/75ZxblBrfr9X47e/vD8zZo1vEwfmzmo1f1O9ZkE4C7dPdehc7plzu+WD9r7TpTraGEFOmnJkiW67bbbZK1VUVGRfv3rXzsdErqJ2nBE/lbGsOYE/cwSDAAAugQKVqCTZs2apWXLljkdhiQdnbk4nY5MTgXntbasjSSFgn7VhSlYAQCA9zHpEgB41ImWtcnJ8quGMawAAKALoGCFK3hhLDWcw/ujdXVNUflP0MJaSwsrAADoAihY4bhQKKSDBw9SlKBV1lodPHhQoVDI6VBcp+4E67DmBv2qYwwrAADoAhjDCsf1799fO3bs0P79+50OxXl79iR+xuPOxuEyoVBI/fv3dzoM16lvOnGXYCZdAgAAXQEFKxwXDAY1ePBgp8Nwh//4j8RPpmHHKVhrVd8ca3XSpZwsJl0CAABdA12CAcCDmqJx+Y1RKz2ClUOXYAAA0EVQsAKAB9WGo8rN8rd6X06WX/UUrAAAoAugYAUAD6prOknBGvSrvpmCFQAAeB8FKwB4UF04qpwTFKzZAZ+ao3FFY0zeBQAAvI2CFQA8qLYpcsIWVmNMsltwLMNRAQAApBYFKwB4UF04qpxg6wWrJOVmBVRHt2AAAOBxFKwA4EH1zVFln7RgZWkbAADgfRSsAOBBDc0xZQdOnMJzg37VNUUyGBEAAEDqUbACgAc1NseUHThxC2soy69aWlgBAIDHUbACgAc1NMeUdZIW1pygX3WsxQoAADyOghUAPKi+KXrSgjUUZAwrAADwPgpWAPCghuaYQrSwAgCALo6CFQA8qL45evIxrEEfY1gBAIDnUbACgAc1NMeUHTx5l+DaMLMEAwAAb6NgBQAPajjFLMHZAb/qm2IZjAgAACD1KFgBwIMamqMnXYc1FPSpvpkuwQAAwNsoWAHAgxqbYwqdoktwPZMuAQAAj6NgBQAPajxFl+BQ0K/6ZroEAwAAb6NgBQAPaozETt4lOOBTAy2sAADA4yhYAcCDGptjyg6evIW1gRZWAADgcRSsAOBBp2xhDfooWAEAgOdRsAKAx8TjVs3RuLJOUrBmB/1qjFCwAgAAb3OkYDXGfM4Y864xZqUx5nFjTMiJOAAgndKV6xojMWUHffIZc8JtQgG/GmlhBZABXNcBSKeMF6zGmH6SPitpqrV2rCS/pA9nOg4ASKd05rqG5phCJ5khWJKCfqNY3CoSi6filADQKq7rAKSbU12CA5JyjDEBSbmSdjkUBwCkU1pyXWIN1pMXrMYYhbIYxwogI7iuA5A2GS9YrbU7Jd0raZuk3ZKqrbUvHL+dMeZWY8xiY8zi/fv3ZzpMAOiUdOa6hkhU2cFTp++coF8NzSxtAyB9uK4DkG5OdAkulnS5pMGS+krKM8Zcd/x21tqHrLVTrbVTy8vLMx0mAHRKOnNdW7oES4mCtb6JFlYA6cN1HYB0c6JL8LmSNltr91trI5KelnS6A3EAQDqlLdcl1mA9dfoO0cIKIP24rgOQVk4UrNskzTDG5BpjjKRzJK12IA4ASKe05bqG5pOvwXpEKOijhRVAunFdByCtnBjD+pakpyS9LWlFMoaHMh0HAKRTOnNdQ3NU2W3oEpwdoIUVQHpxXQcg3QJOnNRa+w1J33Di3ACQKenKdY3NMWW1qYXVr3pmCQaQZlzXAUgnp5a1AQB0UFu7BGcHfGpoooUVAAB4FwUrAHhMY6RtLazZQR8trAAAwNMoWAHAYxqbY8ryt6WF1U8LKwAA8DQKVgDwmDa3sAZ8qqNgBQAAHkbBCgAe065JlyhYAQCAh1GwAoDHNESibV+HlTGsAADAwyhYAcBjEmNY27YOKy2sAADAyyhYAcBjwpF4G7sE+1TfTMEKAAC8i4IVADymMdLWdVj9aqRLMAAA8DAKVgDwmHA7ZgmmYAUAAF5GwQoAHtPmgjXoZ9IlAADgaRSsAOAx4Uhc2f42jGEN+BSOULACAADvomAFAI9pTwtrIwUrAADwMApWAPCYthasIcawAgAAj6NgBQCPCUfbtqxNwO+TldQcjac/KAAAgDSgYAUAD4nHrSLRuIJtGMMqJdZipZUVAAB4FQUrAHhIU7J11WdMm7YPBf1qiETTHBUAAEB6ULACgIc0RmLKbkN34CNygn410MIKAAA8ioIVADwkHIkpO+Bv8/bZTLwEAAA8jIIVADykMRJTdrDtqTsU9Ku+iS7BAADAmyhYAcBDwpGYsto44ZKUaGFtYC1WAADgURSsAOAh4XaOYc0O+OkSDAAAPIuCFQA8pLE5rmB7Ctagj0mXAACAZ1GwAoCHtLuF1e9TQzNjWAEAgDdRsAKAhzRGYspqR8GaFaCFFQAAeBcFKwB4SGM7J12iYAUAAF5GwQoAHtLU7lmCWdYGAAB4FwUrAHhIYyTW7kmXKFgBAIBXUbACgIc0NscVbEcLayjgp0swAADwLApWAPCQxki0XZMuJZa1oYUVAAB4EwUrAHhIY3P7x7DSwgoAALyKghUAPKShuX3L2oQCPjU0UbACAABvomAFAA8JR2LKbleXYL8aInQJBgAA3kTBCgAeEo62r0twKOBTI12CAQCAR1GwAoCHhCPxdi5r41djhIIVAAB4EwUrAHhIY6S9ky75KFgBAIBnUbACgIc0ReLtXtamsTkma20aowIAAEgPClYA8JBwpH2zBAd8Pvl9Rk3ReBqjAgAASA8KVgDwkKZovF1dgiUpFPQz8RIAAPAkClYA8JD2trBKUijgVwPjWAEAgAdRsAKAh4TbOemSJIWCPjU0sRYrAADwHgpWAPCQpmj7Jl2SEl2CG+gSDAAAPIiCFQA8wlqr5g6MYc0O+ChYAQCAJ1GwAoBHNEXjCviNfD7Trv2yg341RugSDAAAvIeCFQA8or1rsB5BCysAAPAqClYA8IhwNKbsgL/d+2UHfGpoomAFAADeQ8EKAB7RkSVtpCMtrHQJBgAA3kPBCgAeEY7Eld3OCZckKSvgYx1WAADgSRSsAOARHW1hzQr46RIMAAA8iYIVADyiM12C65roEgwAALyHghUAPCLcgTVYJSkU9DNLMAAA8CQKVgDwiMbmmIJMugQAALoRClYA8IimaKxjLawBWlgBAIA3UbACgEeEIzEF/abd+2UHfapnDCsAAPAgClYA8IhwJN7BSZf8aqSFFQAAeBAFKwB4RKKFtSOTLrEOKwAA8CZHClZjTJEx5iljzBpjzGpjzEwn4gCAdEp1rgtH4h0qWGlhBZBuXNsBSJeAQ+e9X9LfrbVXGWOyJOU6FAcApFNKc11jJNqhSZeyg8wSDCDtuLYDkBYZL1iNMQWSzpJ0gyRZa5slNWc6DgBIp3TkunAk1qExrKGAX+FIvDOnBoAT4toOQDo50SV4iKT9kh42xrxjjPmlMSbv+I2MMbcaYxYbYxbv378/81ECQOekPNc1Nne0S7BP4UhM8bht974A0AanzHdc1wHoKCcK1oCkyZIetNZOklQv6c7jN7LWPmStnWqtnVpeXp7pGAGgs1Ke6zrawurzGWUHfQpHGccKIC1Ome+4rgPQUU4UrDsk7bDWvpX8+yklkhwAdCUpz3WN0ViHxrBKiW7B9U0UrADSgms7AGmT8YLVWrtH0nZjzMjkTedIWpXpOAAgndKR6zq6DqskhbL8TLwEIC24tgOQTk7NEvwZSY8lZ5HbJOlGh+IAgHRKaa5rbI52uGDNCdLCCiCtuLYDkBaOFKzW2qWSpjpxbgDIlFTnuqZIvBNdgn1qjNDCCiA9uLYDkC5OjGEFAHRAONqxSZckKUQLKwAA8CAKVgDwiHAnWlizgz7GsAIAAM+hYAUAj2iKxpQVMB3aN5tZggEAgAdRsAKARzRF4soK+Du0b3bAp4YIBSsAAPAWClYA8IimaCe6BAd8amiiSzAAAPAWClYA8ABrbbJLcMfSdlbAr3oKVgAA4DEUrADgAZGYlTFGfl/HxrCGgj7VN9MlGAAAeAsFKwB4QDgaU3YHW1elxKRLdWFaWAEAgLdQsAKAB4QjnStYQyxrAwAAPIiCFQA8IDFDcGcKVj9dggEAgOdQsAKAB4QjHZ9wSUoWrEy6BAAAPKZNVz/GmD8ZYy4xxlDgAuiy3JzrwpGOL2kjSaGATw20sAKQu3MdAByvrYnqQUkfkbTeGPM9Y0xlGmMCAKe4NteFozFlBfwd3j876GcMK4AjXJvrAOB4bSpYrbX/tNZ+VNJkSVskvWiMWWCMudEYE0xngACQKW7OdeFITFn+ji1pI9HCCuDf3JzrAOB4be4KYowplXSDpJslvSPpfiUS3YtpiQwAHODWXBdOwaRLjRSsAJLcmusA4HiBtmxkjHlaUqWk30p6v7V2d/KuJ40xi9MVHABkkptzXTgSU7AzY1iDfjVEKFgBuDvXAcDx2lSwSvqltfavLW8wxmRba5ustVPTEBcAOMG1ua6zswQH/UaxmFUsbiV1vGsxgC7BtbkOAI7X1qufe1q57Y1UBgIALuDaXBeOdm6WYGOMQkGf6pl4CYCLcx0AHO+kLazGmN6S+knKMcZM0r+/li+QlJvm2AAgI7yQ68LNnesSLEmhrCNrsTKnCtAdeSHXAcDxTtUl+AIlBuT3l/SjFrfXSvpKmmICgExzfa4LR2IKdGKWYEnKDR4pWAF0U67PdQBwvJMWrNbaRyU9aoy50lr7pwzFBAAZ5YVc1xiJdapLsJRoYa1rYuIloLvyQq4DgOOdqkvwddba30kaZIz5f8ffb639USu7AYCneCHXdXbSJUnKoYUV6Na8kOsA4Hin6hKcl/yZn+5AAMBBrs91jZGYQgF/p44RCvpVR8EKdGeuz3UAcLxTdQn+efLnf2cmHADIPC/kusZITAWhzk2WFAr4aGEFujEv5DoAOF6b+pcZY75vjCkwxgSNMS8ZYw4YY65Ld3AAkEluznXhSLzTXYJDdAkGIHfnOgA4Xluvfs631tZIulTSDkkjJH0hbVEBgDNcm+vCqZh0KcikSwAkuTjXAcDx2nr1c6Qf2sWSHrfWHkpTPADgJNfmulRMupQd8KmuKZKiiAB4mGtzHQAc71STLh3xnDFmjaRGSZ82xpRLCqcvLABwhGtzXTgST00La5guwQDcm+sA4Hhtuvqx1t4paaakqdbaiKR6SZenMzAAyDQ357qmSEzBFCxrU8sYVqDbc3OuA4DjtbWFVZJGKbFuV8t9fpPieADAaa7MdeFoalpYmXQJQJIrcx0AHK9NBasx5reShkpaKunIjB1WJDYAXYibc10qxrCGgj66BANwda4DgOO1tYV1qqTR1lqbzmAAwGGuzXXhSEzZKegSXM8swQBcnOsA4HhtvfpZKal3OgMBABdwba5riqZgHdYsv+qaaWEF4N5cBwDHa2sLa5mkVcaYhZKajtxorb0sLVEBgDNcm+uaIp0vWHOCfjU0RZWVopgAeJZrcx0AHK+tBevd6QwCAFzibqcDaE0kFpckBXwpmHSpOUbBCuBupwMAgLZqU8FqrX3FGDNQ0nBr7T+NMbmS/OkNDQAyy625rjESU3awc8WqlGxhbY6qOAUxAfAut+Y6AGhNm66AjDG3SHpK0s+TN/WT9EyaYgIAR7g116ViwiVJCvqN4nGJeVaA7s2tuQ4AWtPWK6D/lHSGpBpJstaul9QzXUEBgENcmevCzXFlBzrf+GGMUU6WX7E4BSvQzbky1wFAa9pasDZZa5uP/JFcZJorHgBdjStzXWOKWlglJQpWWliB7s6VuQ4AWtPWK6BXjDFfkZRjjDlP0h8lPZe+sADAEa7MdeFIrNMzBB+RG6SFFYA7cx0AtKatV0B3StovaYWkT0r6q6SvpisoAHCIK3NdYwoLVroEA5BLcx0AtKatswTHjTHPSHrGWrs/vSEBgDPcmutS2sJKwQp0e27NdQDQmpNeAZmEu40xByStkbTWGLPfGPP1zIQHAOnn9lyXqlmCpUQLa5SCFeiW3J7rAKA1p7oCukOJWeSmWWtLrbUlkqZLOsMY87l0BwcAGXKHXJzrwpG4gv4UFayMYQW6szvk4lwHAK051RXQxyVda63dfOQGa+0mSdcl7wOArsDVua4xElMWBSuAznN1rgOA1pzqCihorT1w/I3J8Q7B9IQEABnn6lyXyjGsIQpWoDtzda4DgNac6gqouYP3AYCXuDrXNUZiCvpNSo6Vm+VXNB5PybEAeI6rcx0AtOZUswRPMMbUtHK7kRRKQzwA4ARX57pwc0xBvz8lx8rJCtDCCnRfrs51ANCakxas1trUXCEBgIu5Pdc1pHhZG2YJBront+c6AGhNaq6AAABp09icumVtWIcVAAB4CQUrALhcKmcJzqVLMAAA8BAKVgBwucbm1HYJpmAFAABeQcEKAC6XymVtWIcVAAB4CQUrALhcYyTFY1itlUTRCgAA3I+CFQBcLhyJp6yFNeD3yUiikRUAAHgBBSsAuFw4hZMuSZLPZ+gWDAAAPMGxgtUY4zfGvGOMmetUDACQbqnIdYkuwalbPtFvDGuxAkgprusApIuTLay3S1rt4PkBIBM6neuaInFlBUyKwpH8tLACSD2u6wCkhSMFqzGmv6RLJP3SifMDQCakKtclZglOXQurzxjF4vGUHQ9A98Z1HYB0cqqF9T5JX5R0wismY8ytxpjFxpjF+/fvz1hgAJBC9ykFua4pGk/5GFa6BANIofvEdR2ANMl4wWqMuVTSPmvtkpNtZ619yFo71Vo7tby8PEPRAUBqpCrXWWvVFE3dOqyS5DdSLEbBCqDzuK4DkG5OtLCeIekyY8wWSU9IOtsY8zsH4gCAdEpJrmuKxuX3Gfl9qR3DSgsrgBThug5AWmW8YLXWftla299aO0jShyW9bK29LtNxAEA6pSrXNTbHFAqmbvyqlBjDGo0xhhVA53FdByDdWIcVAFwssaRNalO132cUoYUVAAB4QMDJk1tr50ma52QMAJBuncl1DWloYfX7jMLRWEqPCQBc1wFIB1pYAcDFwmlqYY0y6RIAAPAAClYAcLGG5piyU7gGqyT5jVGMLsEAAMADKFgBwMUaIzFlB9PQwkrBCgAAPICCFQBcrLE5mvIuwT4fLawAAMAbKFgBwMUaIzFl+VPcwmqM4nGrCEvbAAAAl6NgBQAXa2iOKSvFLaxSoltwdWMk5ccFAABIJQpWAHCxxjRMuiRRsAIAAG+gYAUAF2tsjinoNyk/rt9nVNVAwQoAANyNghUAXKwxkr4W1hpaWAEAgMtRsAKAi9U3RdMyhtVnjKoam1N+XAAAgFSiYAUAF2toTv06rBJdggEAgDdQsAKAizWkcdKlg3W0sAIAAHejYAUAF0uMYU1PC+uBuqaUHxcAACCVKFgBwMUamqNpKVgDPqOD9RSsAADA3ShYAcDFws3xtHUJPkCXYAAA4HIUrADgYg2R9MwSHPAZHaqnYAUAAO5GwQoALhaOxBVKyxhWnw5TsAIAAJejYAUAFwtHYmlpYfX7jOqbYorG4ik/NgAAQKpQsAKAizVGYsoOpn4Mq5HUIxTQoQZaWQHAi6y1TocAZETA6QAAACcWTtOyNpJUmBPUofpm9ewRSsvxAQCpt3R7lb7z19VavqNKFcW5+vScobpicn+nwwLShoIVAFwqGosrHk9MkJQOBTkBHWKmYADwjN++sUU/enGdrpk2QLfMGqJtB+v1P39fq/11Tbr1rKFOhwekBV2CAcClEt2BfTImPQVrj1BQB5h4CQA84dEFm/XTf23UN94/RrNHlCs/O6DRfQv11UtG6eevbNKSrYedDhFICwpWAHCpxub0dQeWkmNY65rSdnwAQGr84909euClDfrKxZXqVXDsMI7S/GxdN2OgvvDHZWqOMpEeuh4KVgBwqYbmmHKzUj/h0hH52QEdpIUVAFzt3V3V+tJTy/W580ao/ARzDkwfXKKCnKCeeWdnhqMD0o+CFQBcqr45qlAaZgg+ojAnS3traGEFALfaVxPWJx5ZrI/PHKSh5fkn3M4Yo0vH99H/zdugWJzZg9G1ULACgEs1NMfSWrAW5wW1pyactuMDADquvimqGx5epLNGlGnm0NJTbj+6T4GyAj69uGpvBqIDMoeCFQBcqr4pqlAgfQVrSW6W9lZTsAKA2zQ0R3XDwwvVpzCkD0zs16Z9jDE6p7KXHl+4Lc3RAZlFwQoALlXflJglOF2K87K0r5aCFQDcZE91WNf8/E3lZwd005mD2zVT/GmDS7Rk62Hto/cMuhAKVqRUNBbXkq2H9MTCbZq/4YAam2NOhwR4Vn1zNK0Fa2EoqNpwlFklAcAFqhsj+vXrm3TR/a9qTN8C3TJriHztXNYsFPTrtMHF+tPbO9IUJZB5AacDQNexYMMBfe3ZlYpZq4EledpXG9aB2mY1N5yl4twsp8MDPKchzV2CfT6j4txEK2v/4ty0nQcAkGCt1bu7avTW5kPacbhBteGoasIR7TjcqK0H6jW+f6G+fNEoVZR0PCefMbRMf1yyQ/8xZ1gKIwecQ8GKlHjsza364YvrdOPpgzRlYPHR7iurdtfoc7+qV6Q4Lqn1qdgBtK6+OaasNK7DKkkleYmZgilYASC9Vu6s1p1/Wq6D9c0a369QZT2yVZQbVN/CHJ0xtEwVxbnKScFSZpW9C7SnOqxtBxs0oJTcDu+jYEWnPfbWVv3vvzboa5eMVu/CY4vS0X0KNKA0V1sP1uvlNdU6u7KXQ1EC3lPfFFV2GltYpcRMwXsZ6wQAafWvNfv0uT8s1YenDdBZw8vaNS61vXw+o6mDivW3lbv1ydlD03YeIFMYw4pOeW39ft37j7X64gWV7ylWj8jy+9SvKFdf+ONyHa5vznCEgHfVN0UVSuMYVkkqzs2iYAWANFq2vUqf+8NS/b9zR2j2iPK0FqtHTBlYoudX7E77eYBMoGBFh+2rCev2J5bqtrOHn7BYPSI3y6/TBpfoW3NXZSg6wPvq0jyGVZIKcoLazdI2AJAW9U1R3fb427p+5iAN79UjY+cd27dAG/fXaX9tU8bOCaQLBSs6JB63+tyTS3X2yJ4a3aegTft8aGqFXl2/X8u2V6U3OKCLqG+Opb2FtSQ3S7urGtN6DgDorh54ab0Gl+VpxpDSjJ434PdpfP8izVu7L6PnBdKBghUd8uTi7dpX26QPTGrbYtZSYqr1yyb01Q9fWJfGyICuo74pquxgeltYy/KztJOCFQBSbldVox5fuE3XTB3gyPnH9yvUP1fvdeTcQCpRsKLd9tc26ft/X6NPnDlYfl/7xmHMGdlTq/fU6J1th9MUHdB1NDTHFEpzwdqzIKQdhylYASDVHnhpvc6u7KmSPGeW9ptYUaQFGw/KWuvI+YFUoWBFu31r7irNGl6ugaV57d436PfpknF99OC8jWmIDOhaEuuwpr9LcFVDROFILK3nAYDu5FB9s+Yu360Lx/ZxLIai3Cz1KQypNhx1LAYgFShY0S5Lth7Wgo0HdEU7ugIf76zh5Xpj00HtrqZVBziZ+gy0sPp8RuU9smllBYAU+v1bW3Xa4GIV5gQdjWNcv0JVNbJCA7yNghVtFo9bff3ZlfrQ1IpOXUTnZPl1xrAyPfbmthRGB3Q9Dc3RtBesktSrIFvbDzWk/TwA0B3E41a/fXOrzhvd2+lQNL5/kaoaIk6HAXQKBSva7NllOxWJxXXGsLJOH+vcUb30+4XbFInFUxAZ0DU1ZGCWYEkqz8/WNgpWAEiJNzYdVH52QIM6MHQq1YaW56spGud6C55GwYo2CUdi+p+/rdW10wbIl4IFr/sV5ah3QUivrN2fguiArsdaq3Akpuw0r8MqSWU9srXlYH3azwMA3cEfF29PyZf7qeD3GeVlB2hlhadRsKJNHlmwRQNKc1XZxjVX2+L0oaX645LtKTse0JWEI3EF/L52z8TdET17hLT1IC2sANBZDc1R/XP1Ps3M8LqrJ5OX5VdVA+NY4V0UrDil6saIfv7KRn1oSkVKjztjSKnmbzhIEgVaUd8cVU4Gxq9KiTGsWw7QwgoAnTVv7X4N75mvolxnlrJpTX52QNWNEcXjLG8Db6JgxSn9bN5GTR5QrH7FOSk9bl52QOP7F+r5FbtTelygK2hoiiknA+NXJalPYY52VDWqOcoYJwDojLnLd2nKwGKnwzhGMNlbZ+WuaqdDATqEghUnta8mrMfe2tqpZWxOZsbgUv1l6a60HBvwsvoMzRAsSVkBn3r2yNZmWlkBoMPCkZheXXfAdQWrlGhlfXUd84bAmyhYcVL3/XO9zhpRrtL87LQcf0JFkd7dVa0DdU1pOT7gVZla0uaIipJcrd1bm7HzAUBXs2DjAQ0szXVVd+Aj8rIDennNPqfDADqEghUntO1gg+Yu36X3T+ibtnNkBXyaNKBYf1+5J23nALyoNhxVTlbmCta+hSGt3V2TsfMBQFfzj3f3atKAIqfDaFVull+rd9eqJsxswfAeClac0L0vrNX5Y3qrIBRM63mmDSzRc8voFgy0VNeUuUmXJKmiOFer99DCCgAdYa3Vv9bs08QK93UHliSfMars3UMLNhxwOhSg3ShY0ao1e2r02vr9unhsn7Sfa0JFkVburNbhemYLBo6oDWe2YO1fkqu1FKwA0CGrd9fK7zPqWxhyOpQTGtuvUC+vYRwrvIeCFa36/t/X6tLxfTPSJTEr4NO4/kV6ibEVwFF14cyOYe1TENLhhmaWmQKADnh5zV5NrCiSMelfO7ujJlQUad7afbKW5W3gLRSseI8lWw9rxc5qnTuqV8bOOXlAkf62kuVtgCNqwpGMFqw+n9Gwnvl6Z3tVxs4JAF3Fy2v2aXz/IqfDOKm+hSH5jNEaetPAYyhYcQxrrb7719W6YlI/ZQUy9/aYVFGsNzcdVGNzLGPnBNysNhxRbgYnXZKkoWV5envL4YyeEwC8rjYc0erdtRrVp4fToZyUMUaTBhTpn6v3Oh0K0C4UrDjGvHX7tbc2rLOGl2f0vPmhgIaW5+u19YytACSpJsNjWCVpWK8eWrjlUEbPCQBe9+amQxrZu4eyA5nN2R0xaUCxXlxFwQpvoWDFUbG41XeeX62rp1TI78v8GIwJ/YtIokCSEy2sw3vma8XOasXijG8CgLZ6Ze0+jelb4HQYbTKqdw9t3F+n/bVNTocCtBkFK4565p2dCviMpg50Zkr2KQOL9fKafYpzsQxkfB1WSeoRCqq8R7aW76jK6HkBwMteXX9AY/sVOh1GmwT8Pk3oT7dgeEvGC1ZjTIUx5l/GmNXGmHeNMbdnOga8VzgS0w/+sVbXTBvg2Ax3vQpCys3ya+WuakfOD6RSZ3NdXTia8RZWKdHT4V/M2A2gHbrztd3OqkbVNEY0oCTX6VDabOrAEs1dvsvpMIA2c6KFNSrpv6y1oyTNkPSfxpjRDsSBFn71+mYNKsvVyN7OThjA2Ap0IZ3KdbVNUeUEA2kL7kQm9C9kiSkA7dVtr+3mbzigsf0K5HPxcjbHmzSgSEu3Vam6IeJ0KECbZLxgtdbutta+nfy9VtJqSf0yHQf+7WBdkx56dZOumTrA6VA0sYJxrOgaOpvr6psy3yVYkkb07qEtB+t1oI7xTQDapjtf2726br8q+3hj/OoRoaBfY/sV6kW6BcMjHB3DaowZJGmSpLecjKO7+8E/1uqMYaXqXRhyOhSN6NVDu6oatbcm7HQoQMp0JNfVNTnTJTjg82lSRbH+tnJPxs8NwPu607WdtVZvbDyosX29MX61pdMGl+jpt3c4HQbQJo4VrMaYfEl/knSHtbamlftvNcYsNsYs3r+fpU7SZfXuGv3j3T26YlJ/p0ORJPl9RuMZQ4cupCO5LhqLqzkaV3YG10JuaebQUj29hAsZAO1zsnzXFa/r1u+rU9Bv1KvA+S/822vqwBIt31FNAwE8wZGrIWNMUImE9pi19unWtrHWPmStnWqtnVpentk1QbsLa63u/su7umJSP+VnZ36s3ImM7083FXQNHc119U0x5WYFHJsAbXz/Qm0+UK9tBxscOT8A7zlVvuuK13ULNhzQGA+2rkpSVsCn0wYX65l3djodCnBKTswSbCT9StJqa+2PMn1+/NtfV+zR3pqwzq7s5XQox5hQUaQ3Nx1UUzTmdChAh3Um19U4sAZrSwGfT6cPK9Xji7Y5FgMA7+iu13avbTigUR4bv9rSGcPK9eSi7bKW5QThbk60sJ4h6WOSzjbGLE3+u9iBOLq1huaovjV3lT42c5D8PnfNbFcQCqqiOFdvbjrkdChAZ3Q419U1RZXncK+Hcyt76YmF2xSO8MURgFPqdtd2sbjVos2HNKavdwvWUb17KBqPc70F18v4FZG19nVJ7qqQuqEHXlqvYT3zNdql3wxOqCjSS6v3avaIrtFtCN1PZ3JdXVNUOUHnWlglqU9RjgaV5em5Zbt09dQKR2MB4G7d8dpu1a4aFeVmqSg3y+lQOswYo7Mre+mRBZs1c2ip0+EAJ+ToLMFwxrq9tXp84XZ9dLrzy9icyKSKIr20eh/dVNAt1TrcJfiIC8f01oPzNioe53MIAC3N33hAo/o4u3Z9KswaXqY3Nh5kzgK4GgVrNxOPW3356RW6YlI/V38rOKAkV83RmDbur3M6FCDjasNRhRxuYZWkcf0KZYyYBA0AjvPa+v0a08ebEy61lJsV0Lmjeumn/9rgdCjACVGwdjOPL9qmunBU541y10RLxzPGaNKAYr20muVt0P3UNEaU54IWVmOM3j+hrx54aT29HQAgqTka1zvbqjw94VJLF4ztrb+u3K0dh2llhTtRsHYje2vCuvcfa3XTmYPlc9lES62ZUFGkF1bRsoPup6oholyXLDU1bVCJ6sJRzVvXNdZNBIDOWrajSv2KcpQfckee7qyCUFAXjO6t7zy/2ulQgFZRsHYT1lp96U/LdU5lLw0oyXU6nDYZ27dQq3fXqKqh2elQgIw61NDsijGskuQzRpdP7Ksfv7COVlYAUGL91a7SunrEpRP6aPHWw3pj40GnQwHeg4K1m3hm6U5tOVCvyyf2dTqUNssK+DS2b6HmraVlB93L4YZm5bukhVWSpg8u1eGGZr2+4YDToQCA415d3/UK1uyAXx+bMVBfeGqZ6pqiTocDHIOCtRvYXd2obz63SrfMGqKA31sv+cSKIv3j3T1OhwFkVFVDxFUFq8+XGMv64xfXOR0KADiqoTmqVbtqVNnb+zMEH2/qoBKN7NVDd/15BT1q4Creql7QbtZaff4Py3TuqF4aUp7vdDjtNmlAkV7fcEDN0bjToQAZU+2yglWSTh9apt3VYS3czALzALqvhZsPaWh5nitmck+H62YM1Iod1frZKxudDgU4ioK1i3t4/hbtr2vSZR7qCtxSUW6W+hXl6K3NjKlA91HdGFGeywpWv8/okvF99MBL650OBQAc83oXHL/aUijo1/87b4R+PX+Lfv/WVqfDASRRsHZpa/bU6P6X1us/Zg9TwOfdl3rSgCL9bQXdgtF9VDdGXDn75FnDy7V6d41W7apxOhQAcMRr6w5obD/vr796MqX52frKRaP043+u169f3+x0OAAFa1fV0BzVp3/3tj4yfYB6F4acDqdTpg0s0Qur9igeZzwFuj5rrWrCEeVlua9gDfp9umBMbz34CgvMA+h+DtQ1aUdVg4aU5zkdStr1Lgzpa5eM1sPzN+vuv7yrGNdgcBAFaxf1tWdWakBJrs4aXu50KJ3WpyhHedkBvbO9yulQgLRrjMTk9xllBdyZns8Z1VOvrN2vnVWNTocCABk1f8MBje1b6Olea+1R3iNbX3//GL2z7bBueHihasIRp0NCN9U9PnHdzB8WbdPCzYd0/emDnA4lZaYMKNbfV9ItGF1fVUNEPbKDTodxQrlZAc0aUa6H59NNDED38sra/Rrdt+uOX21NfnZAn79gpPKyA7rsJ69ry4F6p0NCN0TB2sW8u6ta3/7rGn32nOFdaga7aYNL9PzyXUyzji6vqsGd41dbumB0L/1h0XbW6gPQbVhr9dr6Axrfr8jpUDIu4PPp+pmDdM6oXvrggwv09rbDToeEboaCtQs5XN+sW36zWNfPHKj+xblOh5NSA0ty5fMZLdtR7XQoQFpVNTYrP9vdXzaV9whpbL9C/XHxdqdDAYCMWL+vTn6f1Ksg2+lQHHPuqF76xJmDdePDi/Tquv1Oh4NuhIK1i4jG4vr0Y29r6sASzRxa5nQ4KWeM0fTBJXpu2S6nQwHSqrrBfUvatOaCMb31q9c3MxkagG7hX2v2aUL/IhljnA7FUZMHFOuOc4frs0+8o1coWpEhFKxdxLfmrlJjJKYPTa1wOpS0mT64VHOX7+ICGV1aVaM7Zwg+3vCe+coJ+vXSmn1OhwIAaffS6r0a17/I6TBcobJ3gT537gjd/sQ7emvTQafDQTdAwdoFPPbmVv1z9T7d9r5h8vu67jd/FSW5CgX9WryVsRPouqo80sJqjNH5Y3rrl69tcjoUAEir2nBEK3bWaEw3m3DpZEb06qFPzxmmT/5uCWtzI+0oWD3ulXX7de8La/X580d64iK3s84YWsa4OXRpB+qaPPNZnjG4RBv21Wn1bi5WAHRd8zcc1MjePbrUZJapMK5foT4+Y5BufHihdrHUGdKIgtXDVu2q0e1PvKPPnj1cvQtDToeTEWcMK9Pf392jcCTmdChAWuyvbVJhjnuXtWkp4PfpvNG99ItXaWUF0HX9c/VejetX6HQYrjRzaKnOHd1LNzy8kJnjkTYUrB61s6pRNz68UB+fMUiVfbpPF5WSvCwNK8/Xi6v2Oh0KkBZeKlgl6ezKnnph1V7tqwk7HQoApFw8bvXymn2aMrDY6VBc65JxfVRRnKvbfv+2YswzgjSgYPWgg3VN+ugv3tQFY3tr5tBSp8PJuDOGlenxhducDgNIiwN13ipYe4SCOmNYqR5esMXpUAAg5ZbuqFJBKKBeBd2jJ1tHGGN0wxmDdLCuWd/562qnw0EXRMHqMbXhiD7+64WaWFGsi8b2cTocR5w2uESrdtVo84F6p0MBUu5gfbOnClZJunBMH/3+rW2qDUecDgUAUurFd/dqYkWR02G4XsDn02fPHq6/r9yjx97a6nQ46GIoWD2ksTmmGx9epP5FOfrQ1P5Oh+OYoN+ns0aU63dvkhDR9VQ3RlSQ441Jl47oXRjS2H4Feuwtej4A6Fr+/u4eugO3UX4ooP86f4Tu/cdazVvLkmdIHQpWjwhHYrrpkUXKy/br46cP6vYLV59d2VN/WrKDyZfQpUTjVnlZfgV83kvNl47vq1++tonPJIAuY/3eWtU1RTW0PN/pUDyjT2GO7jh3hO54YqmWbq9yOhx0Ed67KuqGwpGYbn50sfw+o1tnDZWvmxerktSrIKThvfJZ4gZdSjRmVZSb5XQYHTKoNE9Dy/P1GD0fAHQRzy/frWmDirt9I0F7jejVQ7fMGqIbH16od3dVOx0OugAKVpc70g1YsvrU7KHy+UiaR1w8ro9+/uomRWNxp0MBUiIaj3tu/GpLH5jUT/83b6PqWdoAQBfw/IrdmjaoxOkwPGnywGJdP3OQrvvlW3p722Gnw4HHUbC6WE04oo/+8k1lB3z6j9nD5KdYPUZl7wL1CAX0t5V7nA4FSIlozHq6YB1UmqfKPgWsywrA89bvrdWh+maN6NXD6VA8a/qQUt08a4hufHiRnlu2y+lw4GEUrC61v7ZJ1/z8DZX3yNYtZw2hZfUELpvQVz96cR2trOgSovG4eoS8NeHS8a6e0l+/nr+ZdVkBeNqzS3dp5tBShmF10uQBxfrShZW65/lV+vLTy1VHDxx0AAWrC209WK8PPjhfY/oW6vqZg0iWJzGhf5Hysvz609s7nA4F6LRozKog5N0WVikxvvx9lT11z/OsxQfAm6y1+vM7O3X60DKnQ+kSBpfl6TtXjNPemrDm/OBfemT+ZjU0U7ii7ShYXWbJ1sP64P8t0AWje+vKyf0Z6H8Kxhh9aGqFfvjCOsbNwfMiHh/DesQHJvbTG5sOasGGA06HAgDt9va2KhkjDSrNdTqULiM3K6BbZg3V584dob+t3KPp33lJtz/xjp5dulPbDzXIWut0iHAxb/c962L+/PYO/ffcVbp11hBNGsCaX201vFcPje5ToHtfWKtvvH+M0+EAHRaJxlWa781ZglsKBf264fRB+sJTy/Xi/ztLuVn8VwPAO55ctF2zhpfRaJAGQ8rzdce5I3SovlmLtxzS4wu36ZtzV6kpEteQsjwNLs/TiF49NKJXD43tV6A+hTlOhwwX4CrCBaKxuL73tzWau3y3vnLRKFWU8I1ee107fYDu/NNyXT6xnyZWFDkdzknVN0W1YV+dth1q0N6asGrCUcXjVrnZfl1V26ScLL+CkZhCQb/ToSLDmmNW5fnZToeREpMHFGvRlkO6+y/v6vtXTXA6HABok4bmqP62crf+58rxTofSpZXkZen8Mb11/pjekhITje463Kjd1WGt2V2jl1bv06b9dcoK+HTGsFKdN7q35ows5wvQbopX3WH7asP6zO/fUTgS0zcvH6MeHh+/5pSCUFAfnzlIt/3+bT3/mVkqzHXH8xiOxPTurhq9s+2w3t52WCt2VGt/XZP6FeWoV0FIhTlB5WT55TNGzdGYDtY3q6kqpmu/9aKmDizWlZP768KxvSleu4loLK7SLlKwStLHZwzSXc+s0HPLdun9E/o6HQ4AnNJfV+xRZe8eKvbomtheVRAKqqBPUJV9Co7eZq3VnuqwVuys1kOvbtKXnlqu80b30kdnDNTkAUW0gHcjFKwOemXdfn3+D8s0e2S5rpjYj5mAO2nGkFKt21urzz7xjn51/VQF/Jkdoh2NxbVhf51W7KjWsu1Vemd7lTbur1P/4lwNLcvT4PJ8vW9kT/UpzDnhEkV9C0OSpP+9dpLe2ValRxds0bfmrtLNswbrxjMGU7h2cT6fUVag60wtkJPl12fOHq6vPbNSlb17aDjLQwBwuUcXbNH5Y3o5HQaUmKekT1GO+hTl6PwxvVXV0KzXNxzQbb9/W8W5Wfrk7CG6eFwfBTN8vYfMo2B1QENzVN/72xr9beUefXL2EI3pW+h0SF3GR04boB++uE7/9cdl+vGHJqbtS4C6pqhW767Rql01WrmzWu/urtHGfXUqy8/W4LI8DSrN01WT+2tweZ6yA+0vMnOzAjpjWJnOGFam7Yca9PQ7O/TI/C36+vvH6OJxvflWsYsKdMEvrQaX5enDp1XopkcX6bnbzlQRrRYAXGrFjmrtqw1rcgXziLhRUW6WLh3fVxeP66N3tlXpF69u0nf/uka3zBqsa04boPxsypquilc2wxZsOKAvPb1cg8vy9Z0PjFO+x9dcdJuA36c7zh2ue19Yq0/+dol+/OGJnU5gzdG4Vu2u0dtbD+udbYe1fGe19taENaAkVwNLc9W/OFcfmlKhASW5yslKfQtoRUmubj9nhNbsqdH3/75Gf1yyXd+/crx6FoRSfi44q6t+Szx7RE/trGrUrb9ZrN/dPKNLtSID6DoeWbBZZ1f2pMeby/mM0ZSBxZoysFgb99fpryt26/6X1uuDk/vr4zMHakh5vtMhIsWoljJkT3VY9zy/Sgs3H9LHZw7SlIF8e5cu2QG/vnhBpX77xhZdfP9r+ublYzRnZM8271/fFNXb2w5r4aZDenPzQa3cVaPeBSEN65mvwWV5OnN4ufoVnbhbb7pU9i7QPR8Yqz8v3akL739N3/vguKOTFaBryPR7KpM+PHWA7n95vb7w1DLdd81EegkAcJV9NWG9sGqv7r2aSeK8ZGh5vj5z9nDtr23SS2v26soHF2hgaZ5+Vh1WUV6W+Gq/a6BgTbPqxoh+/spG/e7NrTpnVC/9z5XjGYeYAUG/TzedOURvbz2su/68UkW5QV05ub9OG1yigaW5ys8OKG6lg/VN2nG4URv21mnZjiq9s+2wNh2o19DyfA3vma+zK3vqU7OHumZWuoDfp6unVGhC/yJ97dmVmr/hgO66ZDQtVl1EV+wSfITPZ/TpOUP13b+u0Q/+sVZfvLDS6ZAA4Khfz9+sM4aVqYDJLz2pvEe2PjxtgK6a0l/Lt1erqjGiHYcbdfv3XtbEiiKN7lugASW56lUQUkleUD1CQeVlB5SX5ecLVA9wx1V4F7S3JqxH5m/R7xdu05SBRfr2FeNU1oVm//SKyQOLNbGiSMt3Vmv+hgN6dMEW7asNKxyJy0oqygmqvEe2+hblaEBJrq6eWqEhZfmuLwBH9Oqhez4wTr94bZOufHCBfvaxKepXxFplXpfpicIyLTvg1/87b4T++7l31acwpI/NHOR0SACgmnBEjy/crm9exlruXhfw+TR5YLH6FIakQun2c4Zr04F6rdldo9c3HFBVQ0R14Yjqm2NqaI4qErXKy/arND9bfQtDGt4rX+P6FWn6kBL1L2aZSbegYE2h5mhcr63frycXbdeCjQd1xrBS/fdlY9SLsYaO8vmMJlYUHbM+azxuZYw8/a1afnZAd5wzXH9dsVvv/8nr+vE1EzV7RLnTYaETgl24hfWIgpygvnhhpb41d5XK8rN10bg+TocEoJv71WubNamiiLkhuqCKklxVlJy48IzFreqbo6puiGh/XZN2Hm7Un97ecfT/qMsn9tXVUyvUu5D3hpMoWDshHrfadKBei7Yc0itr92v+xgOqKM7VzKGlun9ahWu6keK9usqECsYYXTK+r4aU5+v/PblUH5k+QHecO6JLj4XsyrrqpEvH61UQ0n+dP1Jf/vMKFeQEdcawMqdDAtBNVTdE9MiCLbr7/bSudkd+n0msARsKqqIkV5MHJOaYiVur9XvrtGDjAT302ibNHlGuz54zXCNYns0RVFRtUNcU1baDDdp2qEHbDtVrw756rdtbq3V7a1UQCmhk7wJV9u6hyyaOZ6FpOGJUn8SETD+dt0GLNh/SAx+ZpJ49+DbQazzc4N9ug8vy9Jmzh+s/f/+2fn3DtKMXCQCQST+dt0FTBxbTgoZj+IzRyN49NLJ3D10zrUL/XL1X1/z8Dc0aXq4vXVTJMKwMo2BtwVqrzQfqtWTrYS3bXqXVe2q1+UC96pui6l0YUq+CkMrys9WrIFvvH99HFSVD1YPB+XCJotwsffnCUfrzOzt10X2v6d6rJ+h9lW2fHRnItNF9CvTJs4boE48s0sM3nnZMt30ASLfthxr0xMJt+u4HxzsdClwsNyugyyb003mjemvuil266L5XdctZQ/TJs4a6fs6TrqLbF6zxuNVbmw/puWW79M/VexW3VpW9CzSoNE8XjOmtfkU5Ks4NenqsI7oPn8/oyin9Nbpvge58ernmjOypr106msW04VoTK4p186whuuHhhfq/j07W6UPpHgwgM741d5XOH9NbJXn0jsOp5WT5dfWUCs0eXq7fvLlVf35np+69egI9hDKg217F1oQjemLhNj26YKuCfqOZQ0v1xQsr1bcwRHEKzxvVp0DfuWKcHntrq8794Sv6zgfH6uzKXk6HBbRq8oBifeZ9w/Sfj72tz18wUh85bQB5GEBa/WvtPq3YWa3v0bqKdupZENJ/nTdCb20+pJsfXawPTOyrL15YybKVadTtCta6pqh++eomPbxgi8b1K9SnZg/V0PI8Lo7Q5eRmBXTLrKFasbNaX31mpSp7b9PXLh2twWV5TocGvMfovoX66iWj9cDL6/Xquv3678vGMqYMQFrUNUV119MrdP3MQXTpRIcYYzRjSKlG9y3Qowu26ML7XtV9H57E0JY06Taf0njc6omF2zTnB//S29sO6+73j9F/vm+YhvXMp1hFlzauX6G+98Hx6lWQrQ/89HXd9ecV2lMddjos4D36FuXom5eNVW5WQOf9+BV949mVWrWrRtZap0MD0IV867lVGtWnQBMoLtBJBaGgPnP2cF02oa9ufHihfvziOkVjcafD6nK6RQvrql01uvNPy9Uci+tz547QkPJ8p0MCMiro9+myCf00Z0RPzV2xS+f9+BVdPK6Pbj1riIbyeYCLZAV8+tDUCp07qpdeXLVXNz2yULG4NL6iUKN6F2hwWZ4GleVqaHm+ipiVHUA7/W3Fbr2ybr++fcVYp0NBFzJzaJlG9i7QL17bpJfX7NP9H55IvZFCXbpgDUdi+vGL6/Tkou360LQKzR5RLh+tqejGCnKC+shpA3XpuL56YdUeXfXgAo3pW6DrZgzUOaN6dZt1QOF+JXlZumZahT40tb/21TZp0/467axq1PIdVdpdHdbOqkYVhIKaPLBIs0eU632VPVnKCcBJbT5Qry8/vUKfv2CkcrO69CUwHFCSl6UvXjBSL6zaqyv+b4G+cMEIfXT6QHpypkCX/bQu2XpI//WHZepTlKPvfnAc38QDLRTkBHXVlApdNqGf3tp8UD95eYO+/PQKXTKujz4wqZ8mDyiWz0eChfOMMepVkFhWrKW4tdpbE9baPbV6btkufWvualX27qGrpvTXxeP7qIAlxwC0UN0Q0Y0PL9RVU/rTswhpY4zRBWN6a2zfQv3s1Y164d29+sHVE97zfxjap8sVrI3NMX3/H2v07NJd+vjMgZo+uNTpkADXygr4NGt4uWYNL9femrAWbDyg//rjMjU0xXTBmF66YGxvTR9cyqQUcB2fMepTmKM+hTmaM7KnIrG4lm6r0p/f2al7nl+tOSPL9aGpFTpjWJn8fPkCdGuNzTF94tFFGtO3UOeMYsZ8pF+/4hx94/2j9Zelu3Thfa/qa5eO1hWT+tHa2kFdqmCdv+GA7vzTcg0uy9N3PziOb9iBduhVENIVk/rrikn9tbOqUYu3HNI9c1drV3WjTh9aqnNG9dKckeV0u4QrBf0+TRtcommDS1QTjuiNjQf1zbmrVNXQrEvH99El4/tqCj0HgG6nsTmmW36zWLnZfn1k+gCnw0E3EvD59MHJ/TVpQLF+8vJ6PfPOTn37inGqKMl1OjTP6RIF64G6Jt0zd7XmbzygG2YO0uSBLOALdEa/ohz1m9hPl0/sp6qGZi3bkWi5+uZzq1RRkqP3jeyp91X21KSKIgUY9wqXKQgFdcGY3rpgTG/tqmrUG5sO6gtPLVNNY1Rnj+ypc0f30pnDy5Sf3SX+CwRwAtUNEX3i0UXKzfLr1llDmccEjhhclqdvXj5Wc5ft1iUPvKZPzh6qm2cNVnaAdVvbytP/WzdH43p0wWb99F8bNWtEmf7ng+OVk8WLD6RSUW6WZo/oqdkjeioaj2v93jot21GlLz21XAfqmnT60DKdXdlTs0eWM0YDrtO3KEdXTu6vKyf3196asJZsPayfvbJRn3tyqcb1K9D7Kntq1vByje5T0OHW17qmqNbvrdWm/fXaXd2oww0RNUfjygr4VJafrYqSHI3s1UNDyvNT0j05FrfadqhBWw/Wa39tkxojMVkr5QT9KsnLUkVJrgaV5XIxhG5t/d5afeLRxRrXv1AfOW0AxSocFfD59IFJ/TRzaKl+++ZWPbFwm75y8ShdOLY33YTbwJMFayQW17NLd+lHL6xV78IcffWS0epXnON0WECXF/D5NKpPgUb1KdCHp0mHG5q1bHuVnl26U/c8v0q9CkKaM7Kn5ows19RBxVwww1V6FYR08bg+unhcH4UjMa3cVa2l26v02FvbVBuOasrAYk0dWKzRfQs0tDxfvQtDx8ycHY7EtLOqUZv312vt3lqt2FGtd3dVa39dk/oX56pPYUgluVnKyw4o6DdqaI5p1a5qvbJun7YebFBNOKLJA4o1a3iZzhhWplG921YkVzdGtGTrIb2x8ZAWbTmkNXtqVJQTVO/CHBXmBBUK+GSM1BSLq6Yxqn21Ye2tadLAklxNHVSs04eW6fShpSrNz07n0wu4Qjxu9bs3t+qHL67TtadVaPaInk6HBBzVqyCkz58/Ust3VOkH/1irn7y8QXecO1znjurFkJWT8FTBWt0Y0R8Xb9evX9+s0vwsfWLWEI3uU+B0WEC3VZyblSxQeyoWt9q4v07Ld1Tpm8+t0vbDDZo8oFizR5Rr5tDSTrVgAakWCvo1dWCJpg4skSQdqm/W2j01WrmrRn9/d492V4V1qL5Z2UGf/D6j5mhccWtVnp+t3oU56lcU0pDyPJ1d2VN9i3La1HJa3RjRmj01WrLlsH7zxlbVNEY0oaJI4/oVamBprkrysuX3SXVNMe2pbtSaPbVavqNaOw83akSvfI3o1UOXjOujz5w97JRLckRicW071KC1e2r1mze26M4/LdegsjydU9lTZ4/qpfH9Cvk8ostZvOWQvjV3lZqjcX2Nxgy42Pj+RRrbr1CLtxzW9/+xVvc8v1ofmzFAV0zurzK+XHwPRwpWY8yFku6X5Jf0S2vt9062fU1jRJ/+3RK9uv6AJg0o0qdmD9XwXj0yEiuAtvH7jEb06qERvXroqilSXTiqd3dVa/GWQ3r0jS2qaYxo0oBizRhSoskDijW2X6HyuvgYwvbmOjinJC9LM4eWaebQsqO3xa1VOBJTPC4F/EbZAV+num4V5gQ1fXDp0dnrDzc0a8PeOm0/3KDVu2tU1xRV3ErZAZ+Kc7PUuzCkG04fpIElue0eKx70+zS0PF9Dy/N18bg+isbiyQK4Sp99/B3VNEZ0+tBSnTm8XNMGFWtoeT4FLDrMyVzXHI3r5TX79Ov5m7XlQL0+OLmfZg0vpwswXM9njE4bXKJpg4q1dm+t5q3dr/tf2qCx/Qp1wZheOn1omYb3JDdLDhSsxhi/pJ9KOk/SDkmLjDF/sdauOtE++2qb1LswpB99aIJ6MPMv4An5oYCmDynV9CH/vjhfm2wxeuadXdp6qF69C0Ia3adAlX0KNKxnvgaV5qmiJKdLfM47kuvgLj5jTtmS2RnFuVlHZzZOt4Dfp7H9CjW2X6E+Ml06WNekFTur9Y939+gnL69XTTii4T0TXzgNLc9T36Ic9SoIqSQvS4U5QfUIBTpdsKNrynSus9Zq68EGvb3tsF5Zt1//WrNPFSW5mj2iXJ85e5gCPiYChLcYY1TZu0CVvQsUjsS0Yke1Xl9/QL94dZOqwxENK8/X4PI8VRTnqjQvMewkK5mPY/G4wpG46puiqg1HVROOqLohoppwRDXhqBqbY2qKxhSJWVlr5TNGWQGfQkG/eoQCKsoJqjQ/Wz0LstWzR0i9CrITa5/3CKkgJ+CanO9E88ZpkjZYazdJkjHmCUmXSzphYivJy9LQ8nztr23S/tqmDIWJVGmM5EmSNu2vczgS9xsSiUnqus9Vzx7Z6tkjW2cOK1MsbrWzqlFbDzXon6v26tE3tuhgXfMx2/fIDqg4L0vFeUEVhBIXzblZAeVm+ZUd8Mnfo7yfQw+lLdqd65qi8Xa/9h15z/CZhCQNKMnVgJJcnT+6l+qaotp2qEE7Dzdqxc4qHapv1qH6ZkVitkPH9hujoN8o6PcpK+hTlt+n7IBPWYHE736/kZGRMYlJpGJxq0gsrmjMKhq3isbjiseTBzNS0Jc4VnbQp5yg/2geyMsOKCfLr1DAr+zkebICPgV8Rv7kP58x8hlJxmjmkFIN65mfsucQkjqQ66REt/Xnl+9WVUOz4jbxPojE44pErZpjMTU0x1TfFFV1Y0QH65q1tyasHYcbdeQd2bNHtkb3KdDNs4aoNC9LkrTtYEMaH6Z3dcec7+XrqdL8LJ1d2VNnV/ZUXVNUOw43and1o+ZvOKC6pkQRGo1bWZvo3ZYVSOTXnKBfOcm8mJcdUFl+trID/qM50RjJ2sRnrykaP/oZW7+3Vou3HFJVY0SH65tV3xw7Jp6Az6gkL0vFuVkqyg2qRyio/Gy/crMDygn6j+b2oP/fufdI3vUl/37/hL6dWm7UWNux/4w6fEJjrpJ0obX25uTfH5M03Vp723Hb3SrpVkkygaxJgaLeba5U4411AV9OfjSFYWeUl+P3cuwS8TstEX+PqIzxG58/eKqv9qLV+xRrqHbH13/HIdedmpfj93LsUkfjN5IxPsn4ZBJ/yChZdv57A2XgExlrqJY/t7Dd+8XDdQeiVXu2piGk9iqTdKAd2w+01panK5jO6EiukzTSBLO3BUsrRrflHC1fbxuLNsvGY6fYxVW6Z75wBy/HLjkcv/H55PMFjPF1eAbNI5/daPW+TfHGmsNt2KXVXOdEC2tr/5W9p2q21j4k6aEOncCYxdG6g1M7sq8beDl+L8cuEb/TvB7/cch1p+Dl+L0cu9RF4q/e5+n4rbWejf84mcl1Hn+9Pf9582j8Xo5d6iLxp+Cz60RH/x2SKlr83V/SLgfiAIB0ItcB6A7IdQDSyomCdZGk4caYwcaYLEkflvQXB+IAgHQi1wHoDsh1ANIq412CrbVRY8xtkv6hxPTnv7bWvpvi03Soy4mLeDl+L8cuEb/TvB7/UeS6NvFy/F6OXSJ+p3k9/qPIdW1C/M7xcuwS8UtyYNIlAAAAAADagsWqAAAAAACuRMEKAAAAAHAlTxesxpgLjTFrjTEbjDF3tnK/McY8kLx/uTFmshNxtqYNsX80GfNyY8wCY8wEJ+I8kVPF32K7acaYWHKdNtdoS/zGmDnGmKXGmHeNMa9kOsYTacN7p9AY85wxZlky9hudiPNEjDG/NsbsM8asPMH9rv3cOoVc5xxynbO8nO/Ide1HrnMOuc5Z5LpTsNZ68p8SA/s3ShoiKUvSMkmjj9vmYkl/U2KNsBmS3nI67nbEfrqk4uTvF7kl9rbG32K7lyX9VdJVTsfdzue/SNIqSQOSf/d0Ou52xP4VSf+T/L1c0iFJWU7H3iK+syRNlrTyBPe78nPr8tfclc8Zuc798bs117UjftfmO3JdWl5vVz5n5Dr3x0+uS2v8ac91Xm5hPU3SBmvtJmtts6QnJF1+3DaXS/qNTXhTUpExpk+mA23FKWO31i6w1h5O/vmmEuuauUVbnntJ+oykP0nal8ng2qAt8X9E0tPW2m2SZK11y2NoS+xWUg9jjJGUr0RSi2Y2zBOz1r6qREwn4tbPrVPIdc4h1znL0/mOXNdu5DrnkOucRa47BS8XrP0kbW/x947kbe3dxgntjesTSnwz4RanjN8Y00/SFZJ+lsG42qotz/8IScXGmHnGmCXGmI9nLLqTa0vs/ytplBILt6+QdLu1Np6Z8FLCrZ9bp5DrnEOuc1ZXz3du/dw6hVznHHKds8h1p5DxdVhTyLRy2/Fr9LRlGye0OS5jzPuUSGxnpjWi9mlL/PdJ+pK1Npb4MshV2hJ/QNIUSedIypH0hjHmTWvtunQHdwptif0CSUslnS1pqKQXjTGvWWtr0hxbqrj1c+sUcp1zyHXO6ur5zq2fW6eQ65xDrnMWue4UvFyw7pBU0eLv/kp869DebZzQpriMMeMl/VLSRdbagxmKrS3aEv9USU8kk1qZpIuNMVFr7TMZifDk2vreOWCtrZdUb4x5VdIESU4ntrbEfqOk79nEwIENxpjNkiolLcxMiJ3m1s+tU8h1ziHXOaur5zu3fm6dQq5zDrnOWeS6U2nvoFe3/FOi2N4kabD+PUB5zHHbXKJjB/kudDrudsQ+QNIGSac7HW9H4j9u+0fkrsH5bXn+R0l6KbltrqSVksZ6JPYHJd2d/L2XpJ2SypyO/bgYB+nEg/Nd+bl1+WvuyueMXOf++N2a69oRv6vzHbku5a+3K58zcp374yfXpf0xpDXXebaF1VobNcbcJukfSsyu9Wtr7bvGmE8l7/+ZErOYXaxEgmhQ4tsJx7Ux9q9LKpX0f8lvs6LW2qlOxdxSG+N3rbbEb61dbYz5u6TlkuKSfmmtbXW67kxq43P/LUmPGGNWKJEcvmStPeBY0McxxjwuaY6kMmPMDknfkBSU3P25dQq5zjnkOmd5Pd+R69qHXOcccp2zyHVtOEey8gUAAAAAwFW8PEswAAAAAKALo2AFAAAAALgSBSsAAAAAwJUoWAEAAAAArkTBCgAAAABwJQpWAAAAAIArUbACAAAAAFzp/wMw61inuLW1SwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.subplot(131)\n",
    "sns.kdeplot(best_network.Yt_hat[idx[0]], shade=True)\n",
    "plt.axvline(MC_pred[idx[0]], color=\"blue\", label = \"MC mean pred.\")\n",
    "plt.axvline(standard_pred[idx[0]], color='red', label = \"Single dropout pred.\")\n",
    "plt.legend()\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "plt.subplot(132)\n",
    "sns.kdeplot(best_network.Yt_hat[idx[1]], shade=True)\n",
    "plt.axvline(MC_pred[idx[1]], color=\"blue\", label = \"mc pred\")\n",
    "plt.axvline(standard_pred[idx[1]], color='red', label = \"single pred.\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "plt.subplot(133)\n",
    "sns.kdeplot(best_network.Yt_hat[idx[2]], shade=True)\n",
    "plt.axvline(MC_pred[idx[2]], color=\"blue\", label = \"mc pred\")\n",
    "plt.axvline(standard_pred[idx[2]], color='red', label = \"single pred.\")\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "plt.suptitle(\"Illustration of Predictive Distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "po6kPdFDMB40"
   },
   "source": [
    "The figures above illustrate how well MC dropout is able to capture the multimodality of the posterior predictive distribution. We tend to observe a distribution with a strong spike for predictions about which the model is rather certain, while the distribution is flatter for instances about which the model is more uncertain.\n",
    "\n",
    "Next, we will examine the measure of predictive uncertainty, the variation ratio, in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NblSjZ8kMB40",
    "outputId": "944f13db-f2a2-42fb-edbc-07c3f1a2baf5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.kdeplot(best_network.VR, shade=True)\n",
    "plt.title(\"Variation Ratio\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAw6IcvMMB41"
   },
   "source": [
    "While our model seems to be relatively certain about most predictions that it puts out, there appears to be a rather significant number of inputs for which this is not the case. We should be careful for observations where the VR is high, as we are not able to trust the model to be right here.\n",
    "\n",
    "Additionally, we will visualize the predictive distribution for the two cases where the VR attains the lowest and highest value, respectively. This illustrates instances of high predictive certainty and high predictive uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kQuUvvNMB41",
    "outputId": "22b006b6-9560-4058-fd5a-60e632e4271d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "lowest_vr = np.argmin(best_network.VR)\n",
    "\n",
    "sns.kdeplot(best_network.Yt_hat[lowest_vr], shade=True)\n",
    "plt.axvline(standard_pred[lowest_vr], color='red', label = \"Single dropout pred.\")\n",
    "plt.axvline(MC_pred[lowest_vr], color=\"blue\", label = \"MC mean pred.\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(0, 10)\n",
    "plt.title('Case with lowest VR\\n MC Predictive Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCYPww9eMB41",
    "outputId": "57bd6e7f-0b90-41e6-a030-b0fc01a187fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "highest_vr = np.argmax(best_network.VR)\n",
    "\n",
    "# notice multimodal distribution\n",
    "sns.kdeplot(best_network.Yt_hat[highest_vr], shade=True)\n",
    "plt.axvline(standard_pred[highest_vr], color='red', label = \"Single dropout pred.\")\n",
    "plt.axvline(MC_pred[highest_vr], color=\"blue\", label = \"MC mean pred.\")\n",
    "plt.legend()\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(0, 10)\n",
    "plt.title('Case with highest VR\\n MC Predictive Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjiUsFYoMB42"
   },
   "source": [
    "Finally, we quickly examine the overall trend of how the mean prediction we obtain via MC integration differs from the prediction of a standard network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4XPEF4pMB42"
   },
   "outputs": [],
   "source": [
    "# what is the mean deviation of the standard NN's prediction from the MC mean?\n",
    "deviation = np.subtract(MC_pred.reshape(-1, 1), standard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkTQvFLEMB43",
    "outputId": "800dc2f0-78e2-4d9c-86c3-5960b86f774e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.histplot(deviation.ravel(), bins = 40, stat = 'density')\n",
    "plt.title('Mean deviation - \\nMC mean prediction and standard prediction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx7uq0qGMB43"
   },
   "source": [
    "While they tend to be quite similar on average, there is a quite noticeable spread and the magnitude of the deviation is high for a few instances. This was to be expected as we essentially perform model averaging in MC dropout, which tends to improve our mean predictions and makes them more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3f14v8SMB44"
   },
   "source": [
    "#### Head-to-head comparison\n",
    "\n",
    "Lastly, we compare the training and test times across the network incorporating variational inference and the network for MC dropout. Additionally, we contrast the test time of the dropout network and a standard neural network.\n",
    "\n",
    "Here, we expect the network incorporating MC dropout to have a training time that is equivalent to that of a normal neural network and drastically shorter than the model trained with ADVI.\n",
    "The dropout neural network should have a test time that is roughly equivalent to that of a standard neural network, scaled by the number of stochastic forward passes, which we set to 1,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ILsUa0sMB44"
   },
   "outputs": [],
   "source": [
    "# evaluate test time, compare to standard NN / VI NN\n",
    "\n",
    "# standard NN with dropout\n",
    "start = time.time()\n",
    "best_network.model.predict(X_val, batch_size=500, verbose=0)\n",
    "test_time1 = time.time() - start\n",
    "\n",
    "# MC dropout\n",
    "start = time.time()\n",
    "best_network.predict(X_val, 1000) # 1000 forward passes\n",
    "test_time2 = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJlEOW0pMB44",
    "outputId": "d3e8d5eb-1faf-4c9a-956f-cb3d730fd682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVI neural network - training time: 2h18min8s.\n",
      "Dropout neural network - training time: 220.238s.\n",
      "-------------------------------------------------\n",
      "Standard neural network - test time: 5.571s.\n",
      "Dropout neural network - test time: 1075.438s.\n"
     ]
    }
   ],
   "source": [
    "# training and test times across models\n",
    "\n",
    "print(f\"ADVI neural network - training time: 2h18min8s.\")\n",
    "print(f\"Dropout neural network - training time: {best_network.running_time:.3f}s.\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Standard neural network - test time: {test_time1:.3f}s.\")\n",
    "print(f\"Dropout neural network - test time: {test_time2:.3f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "va47z40GMB46"
   },
   "source": [
    "Examining the results, we are able to confirm our initial beliefs with regard to the training and test times of the different networks. Notably, there exists a stark contrast between the training times of the network using ADVI and that using dropout. Furthermore, the test time of MC dropout is drastically higher than that of the standard network, as we would expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAaJ_IChMB48"
   },
   "source": [
    "### 7. Discussion <a name=\"discussion\"></a>\n",
    "\n",
    "The goal of this study was to illustrate two practical approaches for performing uncertainty quantification in deep learning models.\n",
    "Gal (2016) claimed that \"over-parametrized\" models result in better uncertainty estimates than smaller models. This is due to models with a large number of parameters being able to capture a larger class of possible functions. Thus, they are able to fit the data better, which consequently results in larger uncertainty estimates further away from the data. Although the models we presented in this work are rather shallow with a relatively small number of parameters and would usually not be called \"deep\" neural networks, the insights we derived are directly applicable to network architectures with more hidden layers.\n",
    "\n",
    "The two methods we use allow us to obtain different views on the uncertainty for a given network: With variational inference (in the form of ADVI), we are able to model the uncertainty about the network weights and can thus quantify the inner workings of a networks; while with MC dropout, we cannot visualize or in effect quantify what happens within the network, but we are able to obtain visualizable posterior distributions for individual inputs, for which we subsequently are able to easily calculate the moments such as the mean or the variance.\n",
    "\n",
    "Both techniques have their advantages and disadvantages, some of which we were able to confirm in our application, which we will summarize in the following.\n",
    "\n",
    "Variational inference originally overcame some of the limitations of performing Bayesian inference in neural networks and made it scalable to large data sets for the first time. It is faster than traditional methods that rely on sampling such as MCMC. This technique naturally incorporates uncertainty quantification and can be used for a wide range of models of varying complexity.\n",
    "\n",
    "On the other hand, it simplifies the posterior approximation. The key to variational inference is that we choose a simple parametrized distribution that is able to capture some of the characteristics of the true posterior distribution that we are trying to estimate such as the general shape and the mode. This comes at the cost of being unable to capture the true distributions' complexity. Additionally, this technique is computationally intensive and rather difficult to use for non-experts.\n",
    "\n",
    "MC dropout is faster than all the traditional approaches to performing approximate inference. In addition to enabling uncertainty quantification, it often comes with an improvement in the data fit of the model (as measured by the predictive log-likelihood) and smaller loss compared to past techniques. It is easy to use for non-experts, making it potentially very attractive for practical applications. Furthermore, any model that already makes use of dropout for regularization can easily be modified to permit capturing the model's predictive uncertainty.\n",
    "\n",
    "However, we are unable to differentiate between the different kinds of uncertainty with the simplest form of MC dropout. As mentioned by Gal (2016), the uncertainty that we can measure is uncalibrated. For practical applications, this implies that model uncertainty can be of different scale for different data sets or increase for data points of high magnitude. Lastly, the test time is approximately scaled by the number of stochastic forward passes, which may pose a problem for applications where the time to obtain a prediction is a relevant factor.\n",
    "\n",
    "A general problem of variational inference is that it is known to underestimate the predictive variance, which is however not a problem in practice (Gal, 2016). In many settings, it may also be of importance to decompose the total uncertainty into the two different forms of uncertainty present in the approximate posterior distribution, a problem which we do not address in this work. In our application of MC dropout, we also fail to account for the possibly heteroskedastic aleatoric uncertainty that may be present (Gal, 2016). \n",
    " \n",
    "<!---\n",
    "* shortcomings + how to deal with them (basically: what to improve upon and what to look at in more detail):\n",
    "    * General problem for VI: known to underestimate predictive variance (not a problem in practice) here only able to quantify total uncertainty with MC dropout and heteroskedastic aleaoric uncertainty is not addressed\n",
    "    * To account for the possibly heteroskedastic aleatoric uncertainty, Gal (2016, Ch. 4.6) offers a solution. In many settings, it may also be of importance to decompose the total uncertainty into the two different forms of uncertainty present in the approximate posterior distribution. This is done in Depeweg et al. (2018), but will not be further elaborated on in this essay.\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuznGLEpMB48"
   },
   "source": [
    "### 8. Conclusion <a name=\"conclusion\"></a>\n",
    "\n",
    "In this study, we showed how two different techniques for quantifying uncertainty in deep learning models can be applied to a practical problem in credit risk classification. We highlighted how variational inference is better suited for measuring the uncertainty within the network architecture, notably allowing us to obtain the posterior distribution over the weights over a neural network. On the other hand, we showcased MC dropout as a technique that is highly attractive for practitioners, as it allows for quantifying the predictive uncertainty with relatively little effort. This comes at the cost of not being able to assess the uncertainty of the network parameters.\n",
    "\n",
    "The findings of our work, especially with regard to MC dropout, are of great significance to practitioners in the credit risk sector. Deep learnings models have successfully been applied in credit risk research, e.g., in Addo et al. (2018) and Sirignano et al. (2018), who additionally employ dropout regularization in their networks. Here, it would easily be possible to obtain estimates of the predictive uncertainty of these models as mentioned previously, improving the models' performance and enhancing their transparency. For banks who aim to constantly improve their models' performance while having very high standards for their models' transparency, this has real-world implications.\n",
    "\n",
    "In future work, the techniques we apply in this study could be further enhanced and applied to more complex models.\n",
    "VI is potentially still too computationally expensive to be used in practice, however, it could be useful to employ it for model selection, so that models with more certain parameters are chosen over models with more uncertain parameters, as indicated by a stronger spread of the weights' posterior distributions. MC dropout could be extended to be able to capture heteroskedastic aleatoric uncertainty and to separately quantify the aleatoric and the epistemic uncertainty, as done in Gal (2016) and Depeweg et al. (2018). In addition, it could be explored how to improve the predictive performance by building on the uncertainty quantification. Here, a more elaborate model could be used to obtain predictions about which the original model is particularly uncertain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3VIajSxMB49"
   },
   "source": [
    "### Bibliography <a name=\"bibliography\"></a>\n",
    "\n",
    "* P. M. Addo et al. (2018), Credit Risk Analysis Using Machine and Deep Learning Models, Risks 2018, 6(2):38; https://doi.org/10.3390/risks6020038 \n",
    "* S. Albanesi and D. F. Vamossy (2019), Predicting Consumer Default: A Deep Learning Approach, <i>NBER Working Paper</i>, DOI: 10.3386/w26165.\n",
    "* D. Blei et al. (2018), Variational Inference: A Review for Statisticians, arXiv: 1601.00670.\n",
    "* C. Blundell et al. (2015), Weight Uncertainty in Neural Networks, <i>Proceedings of the 32nd International Conference on Machine Learning </i>, JMLR 37.\n",
    "* S. Depeweg et al. (2018), Decomposition of uncertainty in Bayesian deep learning for efficient and risk-sensitive learning, <i>Proceedings of The 35th International Conference on Machine Learning</i>, PMLR 80.\n",
    "* Y. Gal (2016), Uncertainty in Deep Learning.\n",
    "* Y. Gal and Z. Ghahramani (2016a), Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning, <i>Proceedings of The 33rd International Conference on Machine Learning</i>, PMLR 48:1050-1059.\n",
    "* Y. Gal and Z. Gharamani (2016b), Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference, arXiv: 1506.02158.\n",
    "* A. Gelman et al. (1995), Bayesian Data Analysis, <i>Chapman and Hall</i>, DOI: https://doi.org/10.1201/9780429258411.\n",
    "* I. Goodfellow et al. (2016), Deep Learning, <i>MIT Press</i>, http://www.deeplearningbook.org.\n",
    "* A. Graves (2011), Practical variational inference for neural networks, <i>NeurIPS</i>.\n",
    "* G. E. Hinton et al. (2012), Improving neural networks by preventing co-adaptation of feature detectors, arXiv:1207.0580.\n",
    "* E. Hüllermeier and W. Waegeman (2021), Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods, <i>Machine Learning</i>, 110:457–506.\n",
    "* D. P. Kingma and M. Welling (2013), Auto-encoding Variational Bayes, arXiv:1312.6114.\n",
    "* A. Kucukelbir et al. (2016), Automatic Differentiation Variational Inference, arXiv:1603.00788.\n",
    "* D. Lu et al. (2012), Analysis of Regression Confidence Intervals and Bayesian Credible Intervals for Uncertainty Quantification, <i> Water Resources Research</i>, 48:1-20.\n",
    "* D. J. C. MacKay (1992), A practical Bayesian framework for backpropagation networks, <i>Neural\n",
    "Computation</i>, 4(3):448–472.\n",
    "* D. J. C. MacKay (1995), Bayesian Neural Networks and Density Networks, <i> Nuclear Instruments and Methods in Physics Research </i>, 354:73-80.\n",
    "* T. Minka (2001), Expectation Propagation for Approximate Bayesian Inference, arXiv:1301.2294\n",
    "* R. M. Neal (1996), Bayesian Learning for Neural Networks, <i>Lecture Notes in Statistics</i>, 118, Springer-Verlag New York.\n",
    "* R. M. Neal (1998), Regression and Classification Using Gaussian Process Priors, <i>Bayesian Statistics</i>, 6: 475.\n",
    "* J. A. Sirignano et al. (2018), Deep Learning for Mortgage Risk, arXiv:1607.02470.\n",
    "* N. Srivastava et al. (2014), Dropout: A Simple Way to Prevent Neural Networks from Overfitting, <i>Journal of Machine Learning Research</i>, 15:1929-1958.\n",
    "* N. Tarashev (2009), Measuring Portfolio Credit Risk Correctly: Why Parameter Uncertainty Matters, <i>BIS Working Paper No. 280</i>.\n",
    "* M. Wainwright and M. Jordan (2008), Graphical Models, Exponential Families, and Variational Inference, <i>Foundations and Trends in Machine Learning</i>, 1:1-305.\n",
    "* L. Wan et al. (2013), Regularization of neural networks using dropConnect, <i>ICML-13</i>."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PTA041U2MB4k",
    "hSJXDeS_MB4l",
    "jEZOejSxMB4q",
    "ExY_UULjMB4w"
   ],
   "name": "model_essay_21-07.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
